{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import gurobipy as gp\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, PercentFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T17:55:56.774032Z",
     "start_time": "2025-05-01T17:55:56.152608Z"
    }
   },
   "id": "1cc59124d1d40dc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:55:56.839565Z",
     "start_time": "2025-05-01T17:55:56.836286Z"
    }
   },
   "cell_type": "code",
   "source": "# output generation for paper 2",
   "id": "c1e512b5bbea8333",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# get input paths\n",
    "test_set = \"bm23\"\n",
    "instance_fldr = os.path.join(\"instances\", test_set)\n",
    "test_set_fldr = os.path.join(\"test_sets\", test_set)\n",
    "results_fldr = os.path.join(\"results\", test_set)\n",
    "out_fldr = os.path.join(\"outputs\", test_set)\n",
    "\n",
    "# set filters\n",
    "seed_idxs = [0]  \n",
    "max_indices = 11\n",
    "degrees = [0, 2, 4]\n",
    "term_list = [4, 64]\n",
    "filter_cbc = False\n",
    "max_base_std = 1e10\n",
    "min_termination_time = 1\n",
    "short, medium, long = 60, 600, 3600\n",
    "remove_status_changes = False\n",
    "win_threshold = .1\n",
    "\n",
    "generators = [\"None\", \"New\", \"Farkas\", \"All\", \"NoDisjunction\", \"NoMatrix\", \"NoTerm\", \"NoBasis\"]\n",
    "\n",
    "# set up some mappings\n",
    "cat_map_new_lines = {\n",
    "    \"None\": \"Default\",\n",
    "    \"Farkas\": \"Param Disj,\\nParam Cuts\",\n",
    "    \"Old\": \"Param Disj,\\nCalc Cuts\",\n",
    "    \"New\": \"Calc Disj,\\nCalc Cuts\"\n",
    "}\n",
    "cat_map = {\n",
    "    \"None\": \"Default\",\n",
    "    \"Farkas\": \"Param Disj, Param Cuts\",\n",
    "    \"Old\": \"Param Disj, Calc Cuts\",\n",
    "    \"New\": \"Calc Disj, Calc Cuts\"\n",
    "}\n",
    "perturbation_map = {\n",
    "    \"matrix\": \"Coefficient Matrix\",\n",
    "    \"rhs\": \"Right Hand Side\",\n",
    "    \"bounds\": \"Variable Bounds\",\n",
    "    \"objective\": \"Objective\"\n",
    "}\n",
    "label = {\n",
    "    \"postRootTime\": \"Time after Processing Root nodes\",\n",
    "    \"rootDualBoundTimeSansVpc\": \"Root Processing Time (Minus VPC Generation)\",\n",
    "    \"terminationTimeSansVpc\": \"Time (Minus VPC Generation)\",\n",
    "    \"terminationTime\": \"Time\",\n",
    "    \"nodes\": \"Nodes Processed\",\n",
    "    \"iterations\": \"LP iterations\",\n",
    "}\n",
    "unit = {\n",
    "    \"postRootTime\": \"(seconds)\",\n",
    "    \"rootDualBoundTimeSansVpc\": \"(seconds)\",\n",
    "    \"terminationTimeSansVpc\": \"(seconds)\",\n",
    "    \"terminationTime\": \"(seconds)\",\n",
    "    \"nodes\": \"(1000 nodes)\",\n",
    "    \"iterations\": \"(1000 iterations)\",\n",
    "}\n",
    "limits = {\n",
    "    \"postRootTime\": 7200,\n",
    "    \"terminationTimeSansVpc\": 7200,\n",
    "    \"terminationTime\": 7200,\n",
    "    \"rootDualBoundTimeSansVpc\": 5,\n",
    "    \"nodes\": 10000,\n",
    "    \"iterations\": 37500\n",
    "}\n",
    "bracket_bounds = {\n",
    "    \"short\": (min_termination_time, short),\n",
    "    \"medium\": (short, medium),\n",
    "    \"long\": (medium, long)\n",
    "}\n",
    "param_map = {\n",
    "    \"degree\": \"Degree of Perturbation\",\n",
    "    \"terms\": \"Number of Disjunctive Terms\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:45.810497Z",
     "start_time": "2025-05-01T19:44:45.803371Z"
    }
   },
   "id": "7efbc88147f301fa",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:46.115864Z",
     "start_time": "2025-05-01T19:44:46.111923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# matplotlib settings\n",
    "plt.rc('text', usetex=True)  # use latex fonts\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['figure.titlesize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 14"
   ],
   "id": "559c07334083a9c",
   "outputs": [],
   "execution_count": 154
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check run failures"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "309a347a4f60cab6"
  },
  {
   "cell_type": "code",
   "source": [
    "# check if each folder in test_set_fldr has a corresponding .mps file in instance_fldr\n",
    "# for instance in os.listdir(test_set_fldr):\n",
    "#     if not os.path.isdir(os.path.join(test_set_fldr, instance)):\n",
    "#         continue\n",
    "#     if not os.path.exists(os.path.join(instance_fldr, f\"{instance}.mps\")):\n",
    "#         # remove the folder if the instance is missing\n",
    "#         # shutil.rmtree(os.path.join(test_set_fldr, instance))\n",
    "#         print(f\"Removed {instance} from test set\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:46.467806Z",
     "start_time": "2025-05-01T19:44:46.465956Z"
    }
   },
   "id": "81fbacab12d1c5f6",
   "outputs": [],
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "source": [
    "# running list of strings contained by different error codes\n",
    "# last two are catchalls\n",
    "err = {\n",
    "    \"walltime\": [],\n",
    "    \"bad_alloc\": [],\n",
    "    \"out of memory\": [],\n",
    "    \"takeoffcuts\": [],\n",
    "    \"solver is dual infeasible\": [],\n",
    "    \"solver must be optimal\": [],\n",
    "    \"segmentation fault\": [],\n",
    "    \"no vpcs were made from a new disjunction\": [],\n",
    "    \"must have primalbound >= root lp objective\": [],\n",
    "    \"objective at parent nodes\": [],\n",
    "    \"failed to optimize mip\": [],\n",
    "    \"disjunction does not represent a full binary tree\": [],\n",
    "    \"solver not proven optimal for nodes\": [],\n",
    "    \"unable to open\": [],\n",
    "    \"license\": [],\n",
    "    \"dot product with obj differs from solver\": [],\n",
    "    \"gurobi: error during callback: addCut\": [],\n",
    "    \"cglvpc::setupconstraints: objective at disjunctive term\": [],\n",
    "    \"unable to read file\": [],\n",
    "    \"stats.id == stats_vec\": [],\n",
    "    \"size of our disjunction is not what we expected it to be\": [],\n",
    "    \"dimension must stay fixed\": [],\n",
    "    \"vpcgenerator must be\": [],\n",
    "}\n",
    "\n",
    "# read in cbc acceptable instances from cbc.txt\n",
    "with open(\"cbc.txt\", \"r\") as f:\n",
    "    cbc_instances = f.read().split(\"\\n\")\n",
    "\n",
    "# runs that errored out with new error code\n",
    "other = []\n",
    "\n",
    "# runs that had no errors\n",
    "empty = []\n",
    "\n",
    "# runs that only had warnings\n",
    "warn_strs = [\"warning\", \"prlp is primal infeasible\", \"farkas\", \"x:\", \"x[\", \"b:\",\n",
    "             \"b[\", \"v:\", \"v[\", \"cut:\", \"A_i . x\", \"dot product with obj differs from solver\"]\n",
    "warning = []\n",
    "\n",
    "# series that didn't run\n",
    "no_go = []\n",
    "\n",
    "# track sizes of instances\n",
    "rows, cols, density = {}, {}, {}\n",
    "\n",
    "# map the names\n",
    "names = {}\n",
    "\n",
    "# counts\n",
    "count_series = 0\n",
    "count_instances = 0\n",
    "number_instances = {}\n",
    "\n",
    "# iterate over all expected runs\n",
    "for instance in os.listdir(test_set_fldr):\n",
    "    if not os.path.isdir(os.path.join(test_set_fldr, instance)):\n",
    "        continue\n",
    "    # only look at cbc instances if we ran with cbc\n",
    "    if instance not in cbc_instances and \"gurobi\" not in test_set and filter_cbc:\n",
    "        continue\n",
    "        \n",
    "    # get the number of rows and columns in the instance\n",
    "    mdl = gp.read(os.path.join(instance_fldr, f\"{instance}.mps\"))\n",
    "    rows[instance] = mdl.NumConstrs\n",
    "    cols[instance] = mdl.NumVars\n",
    "    density[instance] = mdl.NumNZs / (mdl.NumConstrs * mdl.NumVars)\n",
    "        \n",
    "    for perturbation in os.listdir(os.path.join(test_set_fldr, instance)):\n",
    "        if not os.path.isdir(os.path.join(test_set_fldr, instance, perturbation)):\n",
    "            continue\n",
    "        # only look at perturbations that were run\n",
    "        p, d = perturbation.split(\"_\")\n",
    "        if int(d) not in degrees:\n",
    "            continue\n",
    "        for terms in term_list:\n",
    "            for generator in generators:\n",
    "                for seed_idx in seed_idxs:\n",
    "\n",
    "                    # set variables for this iterations\n",
    "                    count_series += 1\n",
    "                    stem = f\"{instance}_{perturbation}_{terms}_{generator}_{seed_idx}\"\n",
    "                    file_pth = os.path.join(results_fldr, f\"{stem}.err\")\n",
    "                    series_fldr = os.path.join(test_set_fldr, instance, perturbation)\n",
    "                    current_count = len([f for f in os.listdir(series_fldr) if f.endswith(\".mps\")])\n",
    "                    count_instances += current_count\n",
    "                    names[stem] = instance\n",
    "                    number_instances[stem] = {\n",
    "                        \"expected\": current_count,\n",
    "                        \"recorded\": 0,\n",
    "                        \"generator\": generator,\n",
    "                        \"error\": \"N/A\"\n",
    "                    }\n",
    "    \n",
    "                    # check if the series wasn't run\n",
    "                    if not os.path.exists(file_pth):\n",
    "                        number_instances[stem][\"error\"] = \"no go\"\n",
    "                        no_go.append(stem)\n",
    "                    \n",
    "                    # check if the series ran with no errors or warnings\n",
    "                    elif os.path.getsize(file_pth) == 0:\n",
    "                        number_instances[stem][\"error\"] = \"empty\"\n",
    "                        empty.append(stem)\n",
    "                    \n",
    "                    # track which error codes were thrown\n",
    "                    else:\n",
    "                        # read the file\n",
    "                        with open(file_pth, \"r\") as f:\n",
    "                            text = f.read().lower()\n",
    "                        \n",
    "                        # assign the error file to the appropriate list\n",
    "                        found_code = False\n",
    "                        for code in err:\n",
    "                            if code in text:\n",
    "                                if code == \"dot product with obj differs from solver\":\n",
    "                                    pattern = r\"obj viol from solver: (-?\\d+\\.\\d+)\\. calculated: (-?\\d+\\.\\d+)\"\n",
    "                                    s, c = re.findall(pattern, text)[-1]\n",
    "                                    # if we didn't terminate, this isn't an error, so keep going\n",
    "                                    if abs(float(s) - float(c)) < 1e-3:\n",
    "                                        continue\n",
    "                                err[code].append(stem)\n",
    "                                found_code = True\n",
    "                                number_instances[stem][\"error\"] = code\n",
    "                                break\n",
    "                        if not found_code:\n",
    "                            if all(not line or any(w in line for w in warn_strs) for line in text.splitlines()):\n",
    "                                warning.append(stem)\n",
    "                                number_instances[stem][\"error\"] = \"warning\"\n",
    "                            else:\n",
    "                                other.append(stem)\n",
    "                                number_instances[stem][\"error\"] = \"other\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:46.636987Z",
     "start_time": "2025-05-01T19:44:46.619346Z"
    }
   },
   "id": "bf0cf935eb4aad03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read MPS format model from file instances/bm23/bm23.mps\n",
      "Reading time = 0.00 seconds\n",
      "BM23: 20 rows, 27 columns, 478 nonzeros\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "source": [
    "# check which series didn't run\n",
    "print(no_go)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.128268Z",
     "start_time": "2025-05-01T19:44:47.126024Z"
    }
   },
   "id": "e4302c5a43b44547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "source": [
    "# get the proportion of series that at least got started\n",
    "1 - (len(no_go) / count_series)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.269246Z",
     "start_time": "2025-05-01T19:44:47.266811Z"
    }
   },
   "id": "5c199c411fd4414c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "source": [
    "# out of time - got hung up in code somewhere - ok\n",
    "print(err[\"walltime\"])\n",
    "len(err[\"walltime\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.429776Z",
     "start_time": "2025-05-01T19:44:47.425916Z"
    }
   },
   "id": "2c0c8ca9c8f7caae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "source": [
    "# out of memory - memory is maxed already - this is what it is\n",
    "# todo: figure out where we ran short on memory so we can explain why we dropped them\n",
    "print(err[\"bad_alloc\"] + err[\"out of memory\"])\n",
    "len(err[\"bad_alloc\"] + err[\"out of memory\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.591033Z",
     "start_time": "2025-05-01T19:44:47.588266Z"
    }
   },
   "id": "799f9596fe1bb847",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "source": [
    "# rerun this if want to give more memory to some instances\n",
    "# bad_alloc_names = set(n.split(\"_\")[0] for n in err[\"bad_alloc\"])\n",
    "# mem = pd.read_csv(\"more_memory.csv\", index_col=0)\n",
    "# mem[\"reason\"] = \"hard solve\" \n",
    "# \n",
    "# for n in bad_alloc_names:\n",
    "#     if f\"{n}.mps\" not in mem.index:\n",
    "#         new_row = pd.DataFrame([{'file_name': f\"{n}.mps\", 'memory': 16.0, 'reason': 'big disjunction'}]).set_index('file_name')\n",
    "#         mem = pd.concat([mem, new_row])\n",
    "#     else:\n",
    "#         mem.loc[f'{n}.mps', 'memory'] = 16.0\n",
    "# \n",
    "# mem.to_csv(\"more_memory.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.661731Z",
     "start_time": "2025-05-01T19:44:47.659590Z"
    }
   },
   "id": "25b00b07fb8791bf",
   "outputs": [],
   "execution_count": 161
  },
  {
   "cell_type": "code",
   "source": [
    "# this is an issue with John's bookkeeping - not much we can do here\n",
    "print(err[\"takeoffcuts\"])\n",
    "len(err[\"takeoffcuts\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.740992Z",
     "start_time": "2025-05-01T19:44:47.737400Z"
    }
   },
   "id": "121be7316b7ba6b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"solver is dual infeasible\"])\n",
    "len(err[\"solver is dual infeasible\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:47.832711Z",
     "start_time": "2025-05-01T19:44:47.827153Z"
    }
   },
   "id": "5c8956abcbdf8b6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "cell_type": "code",
   "source": [
    "# these are usually issues with CLP finding optimality - not much we can do here\n",
    "print(err[\"solver must be optimal\"])\n",
    "len(err[\"solver must be optimal\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.018259Z",
     "start_time": "2025-05-01T19:44:48.015471Z"
    }
   },
   "id": "72de71ca5f9b047",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"segmentation fault\"])\n",
    "len(err[\"segmentation fault\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.101325Z",
     "start_time": "2025-05-01T19:44:48.098697Z"
    }
   },
   "id": "fef47bf6e8f3c2d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "source": [
    "# seg_err = {\n",
    "#     \"Bad image at line\": [],\n",
    "# }\n",
    "# \n",
    "# seg_other = []\n",
    "# \n",
    "# for stem in err[\"segmentation fault\"]:\n",
    "#     file_pth = os.path.join(results_fldr, f\"{stem}.out\")\n",
    "# \n",
    "#     with open(file_pth, \"r\") as f:\n",
    "#         text = f.read()\n",
    "#     \n",
    "#     # assign the error file to the appropriate list\n",
    "#     found_code = False\n",
    "#     for code in seg_err:\n",
    "#         if code in text:\n",
    "#             seg_err[code].append(stem)\n",
    "#             found_code = True\n",
    "#             break\n",
    "#     if not found_code:\n",
    "#         seg_other.append(stem)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.192086Z",
     "start_time": "2025-05-01T19:44:48.189621Z"
    }
   },
   "id": "e9b3b21e95de2989",
   "outputs": [],
   "execution_count": 166
  },
  {
   "cell_type": "code",
   "source": [
    "# print(seg_err[\"Bad image at line\"])\n",
    "# len(seg_err[\"Bad image at line\"]) / len(err[\"segmentation fault\"]) if err[\"segmentation fault\"] else 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.229071Z",
     "start_time": "2025-05-01T19:44:48.226764Z"
    }
   },
   "id": "cba75270a86cba0d",
   "outputs": [],
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "source": [
    "# print(seg_other)\n",
    "# len(seg_other)/len(err[\"segmentation fault\"]) if err[\"segmentation fault\"] else 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.275482Z",
     "start_time": "2025-05-01T19:44:48.272527Z"
    }
   },
   "id": "5aecf827954c44de",
   "outputs": [],
   "execution_count": 168
  },
  {
   "cell_type": "code",
   "source": [
    "# # get breakdown of why vpc generation failed - mostly from lack of provisioning\n",
    "# for code, exps in seg_err.items():\n",
    "#     print(f\"{code}: {len(exps) / len(err['segmentation fault']) if err['segmentation fault'] else 0}\")\n",
    "# \n",
    "# print(f\"other: {len(seg_other) / len(err['segmentation fault']) if err['segmentation fault'] else 0}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.359108Z",
     "start_time": "2025-05-01T19:44:48.356898Z"
    }
   },
   "id": "d4a3204609033812",
   "outputs": [],
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "source": [
    "# todo: check aleks' removals and drop those below for similar reasons\n",
    "# todo: check size of disjunctions and decide what to do with those that are too big\n",
    "# these should all be from the problem being too big and hitting the time limit or integer solutions\n",
    "print(err[\"no vpcs were made from a new disjunction\"])\n",
    "missing_4_term = [n for n in err[\"no vpcs were made from a new disjunction\"] if \"_4_\" in n]\n",
    "missing_64_term = [n for n in err[\"no vpcs were made from a new disjunction\"] if \"_64_\" in n]\n",
    "print(f'4 term: {len(missing_4_term) / count_series}')\n",
    "print(f'64 term: {len(missing_64_term) / count_series}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.381628Z",
     "start_time": "2025-05-01T19:44:48.379395Z"
    }
   },
   "id": "323bfdd3f23d8330",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "4 term: 0.0\n",
      "64 term: 0.0\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "source": [
    "# vpc_err = {\n",
    "#     \"CglVPC: Finishing with exit reason: PRLP_TIME_LIMIT\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: TIME_LIMIT\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: NO_CUTS_LIKELY\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: PRLP_INFEASIBLE\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: SUCCESS\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: OPTIMAL_SOLUTION_FOUND\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: FAIL_LIMIT\": [],\n",
    "#     \"CglVPC: Finishing with exit reason: NO_DISJUNCTION\": [],\n",
    "# }\n",
    "# \n",
    "# vpc_other = []\n",
    "# \n",
    "# for stem in err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     file_pth = os.path.join(results_fldr, f\"{stem}.out\")\n",
    "# \n",
    "#     with open(file_pth, \"r\") as f:\n",
    "#         text = f.read()\n",
    "#     \n",
    "#     # assign the error file to the appropriate list\n",
    "#     found_code = False\n",
    "#     for code in vpc_err:\n",
    "#         if code in text:\n",
    "#             vpc_err[code].append(stem)\n",
    "#             found_code = True\n",
    "#             break\n",
    "#     if not found_code:\n",
    "#         vpc_other.append(stem)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.420871Z",
     "start_time": "2025-05-01T19:44:48.418744Z"
    }
   },
   "id": "d10dcdb803b1faa3",
   "outputs": [],
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: PRLP_TIME_LIMIT\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: PRLP_TIME_LIMIT\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.463993Z",
     "start_time": "2025-05-01T19:44:48.462504Z"
    }
   },
   "id": "158f7e03587ca952",
   "outputs": [],
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: TIME_LIMIT\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: TIME_LIMIT\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.505084Z",
     "start_time": "2025-05-01T19:44:48.502457Z"
    }
   },
   "id": "dfb77c5bc34bbe22",
   "outputs": [],
   "execution_count": 173
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: NO_CUTS_LIKELY\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: NO_CUTS_LIKELY\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.583237Z",
     "start_time": "2025-05-01T19:44:48.581547Z"
    }
   },
   "id": "eefe53ee89a87625",
   "outputs": [],
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: PRLP_INFEASIBLE\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: PRLP_INFEASIBLE\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.623310Z",
     "start_time": "2025-05-01T19:44:48.620280Z"
    }
   },
   "id": "933d889bce35d1c6",
   "outputs": [],
   "execution_count": 175
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: SUCCESS\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: SUCCESS\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.697798Z",
     "start_time": "2025-05-01T19:44:48.695722Z"
    }
   },
   "id": "ac8d0ff2a27ba558",
   "outputs": [],
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: OPTIMAL_SOLUTION_FOUND\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: OPTIMAL_SOLUTION_FOUND\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.779856Z",
     "start_time": "2025-05-01T19:44:48.777756Z"
    }
   },
   "id": "4b63d3cd518e3107",
   "outputs": [],
   "execution_count": 177
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: FAIL_LIMIT\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: FAIL_LIMIT\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.862050Z",
     "start_time": "2025-05-01T19:44:48.860248Z"
    }
   },
   "id": "f83387c79d2520a4",
   "outputs": [],
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "source": [
    "# print(vpc_err[\"CglVPC: Finishing with exit reason: NO_DISJUNCTION\"])\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     len(vpc_err[\"CglVPC: Finishing with exit reason: NO_DISJUNCTION\"]) / len(err[\"no vpcs were made from a new disjunction\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:48.946116Z",
     "start_time": "2025-05-01T19:44:48.944270Z"
    }
   },
   "id": "26779878562d1784",
   "outputs": [],
   "execution_count": 179
  },
  {
   "cell_type": "code",
   "source": "# vpc_other",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.029338Z",
     "start_time": "2025-05-01T19:44:49.026892Z"
    }
   },
   "id": "68d93918615c4f37",
   "outputs": [],
   "execution_count": 180
  },
  {
   "cell_type": "code",
   "source": [
    "# # get breakdown of why vpc generation failed - mostly from lack of provisioning/problem being too large\n",
    "# if err[\"no vpcs were made from a new disjunction\"]:\n",
    "#     for code, exps in vpc_err.items():\n",
    "#         print(f\"{code}: {len(exps) / len(err['no vpcs were made from a new disjunction'])}\")\n",
    "#     \n",
    "#     print(f\"other: {len(vpc_other) / len(err['no vpcs were made from a new disjunction'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.116678Z",
     "start_time": "2025-05-01T19:44:49.114968Z"
    }
   },
   "id": "d2dfbc64d74a0662",
   "outputs": [],
   "execution_count": 181
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"must have primalbound >= root lp objective\"])\n",
    "len(err[\"must have primalbound >= root lp objective\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.205389Z",
     "start_time": "2025-05-01T19:44:49.202017Z"
    }
   },
   "id": "cbe5c977488d207f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "source": [
    "# LP relaxation objective is not going to match root nodes objective when warm starting \n",
    "print(err[\"objective at parent nodes\"])\n",
    "len(err[\"objective at parent nodes\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.415040Z",
     "start_time": "2025-05-01T19:44:49.412056Z"
    }
   },
   "id": "e48a519132565dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "source": [
    "# not enough tolerance added to bound (or we hit time limit) - element 2 from 5 and 4 from 4\n",
    "print(err[\"failed to optimize mip\"])\n",
    "len(err[\"failed to optimize mip\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.559310Z",
     "start_time": "2025-05-01T19:44:49.556665Z"
    }
   },
   "id": "f0cec5808fee4f9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "source": [
    "# todo: figure out why\n",
    "print(err[\"disjunction does not represent a full binary tree\"])\n",
    "len(err[\"disjunction does not represent a full binary tree\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.770388Z",
     "start_time": "2025-05-01T19:44:49.767903Z"
    }
   },
   "id": "60ac343575ffea1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bm23_matrix_4_64_New_0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006944444444444444"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "source": [
    "# again issue with not getting through vpc generation in time\n",
    "# todo: handle this gracefully\n",
    "print(err[\"solver not proven optimal for nodes\"])\n",
    "len(err[\"solver not proven optimal for nodes\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.858461Z",
     "start_time": "2025-05-01T19:44:49.855948Z"
    }
   },
   "id": "9e8cf1d6b6dca990",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"unable to open\"])\n",
    "len(err[\"unable to open\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:49.944754Z",
     "start_time": "2025-05-01T19:44:49.941929Z"
    }
   },
   "id": "b6c518ef5d669738",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"license\"])\n",
    "len(err[\"license\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.032070Z",
     "start_time": "2025-05-01T19:44:50.029504Z"
    }
   },
   "id": "7046e5a3187d32a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "source": [
    "print(warning)\n",
    "len(warning) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.130277Z",
     "start_time": "2025-05-01T19:44:50.127271Z"
    }
   },
   "id": "cbcf42c2debaed4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bm23_rhs_0_64_New_0', 'bm23_rhs_4_64_New_0', 'bm23_rhs_2_64_New_0', 'bm23_objective_2_64_New_0', 'bm23_objective_4_64_New_0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.034722222222222224"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 189
  },
  {
   "cell_type": "code",
   "source": [
    "# errors unaccounted for\n",
    "print(other)\n",
    "len(other) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.199702Z",
     "start_time": "2025-05-01T19:44:50.197196Z"
    }
   },
   "id": "f2365025f4ca39d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bm23_objective_0_64_NoDisjunction_0', 'bm23_rhs_4_4_NoBasis_0', 'bm23_matrix_2_64_New_0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020833333333333332"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "source": [
    "# proportion of series that were improperly provisioned\n",
    "(len(err[\"bad_alloc\"] + err[\"out of memory\"] + err[\"walltime\"])) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.281449Z",
     "start_time": "2025-05-01T19:44:50.279234Z"
    }
   },
   "id": "5cc2517a3d1c1f27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "source": [
    "# todo handle this\n",
    "print(err[\"dot product with obj differs from solver\"])\n",
    "len(err[\"dot product with obj differs from solver\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.340054Z",
     "start_time": "2025-05-01T19:44:50.337529Z"
    }
   },
   "id": "e3032aff7dc0df69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "source": [
    "# changed code to ignore this error\n",
    "print(err[\"gurobi: error during callback: addCut\"])\n",
    "len(err[\"gurobi: error during callback: addCut\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.500924Z",
     "start_time": "2025-05-01T19:44:50.498710Z"
    }
   },
   "id": "46ead0b00886a34b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "source": [
    "# largely not replicating - only issue I could find was aleks missing updated objective from CLP when resolving to check this\n",
    "print(err[\"cglvpc::setupconstraints: objective at disjunctive term\"])\n",
    "len(err[\"cglvpc::setupconstraints: objective at disjunctive term\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.600068Z",
     "start_time": "2025-05-01T19:44:50.597774Z"
    }
   },
   "id": "9656878fa4923ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "source": [
    "# not replicating - rerun\n",
    "print(err[\"unable to read file\"])\n",
    "len(err[\"unable to read file\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.683733Z",
     "start_time": "2025-05-01T19:44:50.680143Z"
    }
   },
   "id": "846d115fdb5ceb92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "source": [
    "# not replicating - rerun\n",
    "print(err[\"stats.id == stats_vec\"])\n",
    "len(err[\"stats.id == stats_vec\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.849495Z",
     "start_time": "2025-05-01T19:44:50.847261Z"
    }
   },
   "id": "577cacfb7625a3fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "source": [
    "print(err[\"size of our disjunction is not what we expected it to be\"])\n",
    "len(err[\"size of our disjunction is not what we expected it to be\"]) / count_series"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:50.960277Z",
     "start_time": "2025-05-01T19:44:50.958030Z"
    }
   },
   "id": "9dbd086695fd1686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:51.050292Z",
     "start_time": "2025-05-01T19:44:51.047964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(err[\"vpcgenerator must be\"])\n",
    "len(err[\"vpcgenerator must be\"]) / count_series"
   ],
   "id": "9fee6bee7c0294d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:51.144509Z",
     "start_time": "2025-05-01T19:44:51.142165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(err[\"dimension must stay fixed\"])\n",
    "len(err[\"dimension must stay fixed\"]) / count_series"
   ],
   "id": "f1cac35742f4bf41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "source": [
    "# get breakdown of errors\n",
    "for code, exps in err.items():\n",
    "    print(f\"{code}: {len(exps) / count_series}\")\n",
    "\n",
    "print(f\"other: {len(other) / count_series}\")\n",
    "\n",
    "print(f\"warning: {len(warning) / count_series}\")\n",
    "\n",
    "print(f\"no errors/warnings: {len(empty) / count_series}\")\n",
    "\n",
    "print(f\"no go: {len(no_go) / count_series}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:51.214232Z",
     "start_time": "2025-05-01T19:44:51.211955Z"
    }
   },
   "id": "b10b8b1c2fe3ea2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walltime: 0.0\n",
      "bad_alloc: 0.0\n",
      "out of memory: 0.0\n",
      "takeoffcuts: 0.0\n",
      "solver is dual infeasible: 0.0\n",
      "solver must be optimal: 0.0\n",
      "segmentation fault: 0.0\n",
      "no vpcs were made from a new disjunction: 0.0\n",
      "must have primalbound >= root lp objective: 0.0\n",
      "objective at parent nodes: 0.0\n",
      "failed to optimize mip: 0.0\n",
      "disjunction does not represent a full binary tree: 0.006944444444444444\n",
      "solver not proven optimal for nodes: 0.0\n",
      "unable to open: 0.0\n",
      "license: 0.0\n",
      "dot product with obj differs from solver: 0.0\n",
      "gurobi: error during callback: addCut: 0.0\n",
      "cglvpc::setupconstraints: objective at disjunctive term: 0.0\n",
      "unable to read file: 0.0\n",
      "stats.id == stats_vec: 0.0\n",
      "size of our disjunction is not what we expected it to be: 0.0\n",
      "dimension must stay fixed: 0.0\n",
      "vpcgenerator must be: 0.0\n",
      "other: 0.020833333333333332\n",
      "warning: 0.034722222222222224\n",
      "no errors/warnings: 0.9375\n",
      "no go: 0.0\n"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read in data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T21:45:22.220691Z",
     "start_time": "2024-04-02T21:45:22.181888Z"
    }
   },
   "id": "1b96d76b8971a661"
  },
  {
   "cell_type": "code",
   "source": [
    "# map generator names to the corresponding data frames\n",
    "df_map = {\n",
    "    \"None\": pd.DataFrame(),\n",
    "    \"Farkas\": pd.DataFrame(),\n",
    "    \"New\": pd.DataFrame(),\n",
    "    \"All\": pd.DataFrame(),\n",
    "    \"NoDisjunction\": pd.DataFrame(),\n",
    "    \"NoMatrix\": pd.DataFrame(),\n",
    "    \"NoTerm\": pd.DataFrame(),\n",
    "    \"NoBasis\": pd.DataFrame()\n",
    "}\n",
    "gap_map = {\n",
    "    \"None\": pd.DataFrame(),\n",
    "    \"Farkas\": pd.DataFrame(),\n",
    "    \"New\": pd.DataFrame(),\n",
    "    \"All\": pd.DataFrame(),\n",
    "    \"NoDisjunction\": pd.DataFrame(),\n",
    "    \"NoMatrix\": pd.DataFrame(),\n",
    "    \"NoTerm\": pd.DataFrame(),\n",
    "    \"NoBasis\": pd.DataFrame()\n",
    "}\n",
    "regex = re.compile(r'([a-zA-Z0-9-]+(?:_o)?)_([a-z]+)_([0-9-]+)_([0-9]+)_([a-zA-Z ]+)')\n",
    "solution_pattern = r\"_(\\d+)\\.pb\"\n",
    "\n",
    "# declaring types as needed\n",
    "column_types = {\n",
    "    \"lpBound\": float,\n",
    "    \"lpBoundPostVpc\": float,\n",
    "    \"disjunctiveDualBound\": float,\n",
    "    \"primalBound\": float,\n",
    "    \"rootDualBound\": float,\n",
    "    \"dualBound\": float\n",
    "}\n",
    "\n",
    "skipped_instances = set()\n",
    "primal_bounds = {}\n",
    "same_solution = {}\n",
    "\n",
    "# iterate over all files in the folder\n",
    "for file_name in os.listdir(results_fldr):\n",
    "    \n",
    "    file_pth = os.path.join(results_fldr, file_name)\n",
    "    \n",
    "    # if the file is not a nonempty csv, skip it\n",
    "    if not file_name.endswith(\".csv\") or os.path.getsize(file_pth) == 0:\n",
    "        continue\n",
    "    \n",
    "    # get the experimental set up\n",
    "    match = regex.search(file_name)\n",
    "    instance_name = names.get(file_name[:-4])\n",
    "    if not instance_name:\n",
    "        skipped_instances.add(file_name[:-4].split(\"_\")[0])\n",
    "        os.remove(file_pth)\n",
    "        continue\n",
    "    # instance_name = match.group(1)\n",
    "    perturbation = match.group(2)\n",
    "    assert perturbation in [\"matrix\", \"rhs\", \"bounds\", \"objective\"], f\"Unknown perturbation: {perturbation}\"\n",
    "    expo = int(match.group(3))\n",
    "    assert expo in degrees, f\"Unknown degree: {expo}\"\n",
    "    degree = 2**int(expo)\n",
    "    terms = int(match.group(4))\n",
    "    assert terms in term_list, f\"Unknown number of terms: {terms}\"\n",
    "    generator = match.group(5)\n",
    "    assert generator in generators, f\"Unknown generator: {generator}\"\n",
    "    base_name = f\"{instance_name}_0\"\n",
    "    \n",
    "    # get the primal bounds for this experiment\n",
    "    cur_instance_test_set_fldr = os.path.join(test_set_fldr, instance_name, f\"{perturbation}_{expo}\")\n",
    "    for test_set_file in os.listdir(cur_instance_test_set_fldr):\n",
    "        if test_set_file.endswith(\".pb\"):\n",
    "            with open(os.path.join(cur_instance_test_set_fldr, test_set_file), \"r\") as f:\n",
    "                primal_bounds[perturbation, expo, \".\".join(test_set_file.split(\".\")[:-1])] = float(f.read())\n",
    "                \n",
    "    # see if solution changed\n",
    "    for test_set_file in os.listdir(cur_instance_test_set_fldr):\n",
    "        if test_set_file.endswith(\".pb\"):\n",
    "            perturbation_name = \".\".join(test_set_file.split(\".\")[:-1])\n",
    "            same_solution[perturbation, expo, perturbation_name] = \\\n",
    "                primal_bounds[perturbation, expo, base_name] == primal_bounds[perturbation, expo, perturbation_name]\n",
    "            \n",
    "    # read the file\n",
    "    df = pd.read_csv(file_pth, keep_default_na=False, dtype=column_types, index_col=0)\n",
    "    \n",
    "    for instance_idx in df.index:\n",
    "        \n",
    "        # fill in primal bounds if missing\n",
    "        # df.loc[instance_idx, \"primalBound\"] = min(primal_bounds.get(stem_map.get(instance_idx), 1e100), df.loc[instance_idx, \"primalBound\"])\n",
    "        df.loc[instance_idx, \"primalBound\"] = min(\n",
    "            primal_bounds[perturbation, expo, f\"{instance_name}_{instance_idx}\"], df.loc[instance_idx, \"primalBound\"]\n",
    "        )\n",
    "        \n",
    "        # same with root dual bound\n",
    "        df.loc[instance_idx, \"rootDualBound\"] = df.loc[instance_idx, \"rootDualBound\"] if df.loc[instance_idx, \"rootDualBound\"] < 1e100 else df.loc[instance_idx, \"lpBoundPostVpc\"] \n",
    "    \n",
    "    # get rid of the index so the rest of the notebook works\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # add some identifying columns\n",
    "    df[\"instance\"] = instance_name\n",
    "    df[\"perturbation\"] = perturbation\n",
    "    df[\"degree\"] = degree\n",
    "    df[\"terms\"] = terms\n",
    "    df[\"rows\"] = rows[instance_name]\n",
    "    df[\"cols\"] = cols[instance_name]\n",
    "    df[\"density\"] = density[instance_name]\n",
    "    \n",
    "    # append to the appropriate data frame\n",
    "    df_map[generator] = pd.concat([df_map[generator], df])\n",
    "    \n",
    "    # track recorded vs expected experiments\n",
    "    number_instances[file_name[:-4]][\"recorded\"] = len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:51.994746Z",
     "start_time": "2025-05-01T19:44:51.316735Z"
    }
   },
   "id": "cd620191b5a5849a",
   "outputs": [],
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "source": [
    "# convert number_instances to dataframe\n",
    "frame = pd.DataFrame(number_instances).T\n",
    "frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.013401Z",
     "start_time": "2025-05-01T19:44:52.007793Z"
    }
   },
   "id": "e87e9581360c0bd9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             expected recorded      generator  error\n",
       "bm23_rhs_0_4_None_0                21       21           None  empty\n",
       "bm23_rhs_0_4_New_0                 21       21            New  empty\n",
       "bm23_rhs_0_4_Farkas_0              21       21         Farkas  empty\n",
       "bm23_rhs_0_4_All_0                 21       21            All  empty\n",
       "bm23_rhs_0_4_NoDisjunction_0       21       21  NoDisjunction  empty"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected</th>\n",
       "      <th>recorded</th>\n",
       "      <th>generator</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm23_rhs_0_4_None_0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm23_rhs_0_4_New_0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>New</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm23_rhs_0_4_Farkas_0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>Farkas</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm23_rhs_0_4_All_0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>All</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm23_rhs_0_4_NoDisjunction_0</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>NoDisjunction</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "source": [
    "# redo the runs that have incomplete data that we're not sure should be that way\n",
    "redos = frame.loc[(frame[\"expected\"] > frame[\"recorded\"]) & (frame[\"error\"] != \"no vpcs were made from a new disjunction\")].index.tolist()\n",
    "redos = pd.DataFrame({\"experiment\": redos})\n",
    "redos.to_csv(\"redos.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.069517Z",
     "start_time": "2025-05-01T19:44:52.065642Z"
    }
   },
   "id": "98cfdc27dd6a1772",
   "outputs": [],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "source": [
    "if \"miplib\" in test_set or \"quick\" in test_set:\n",
    "    # group frame by generator and sum remaining columns\n",
    "    gb = frame.groupby([\"generator\", \"error\"]).sum().reset_index()\n",
    "    gb[\"missing\"] = gb[\"expected\"] - gb[\"recorded\"]\n",
    "    total = gb.groupby(\"generator\")[[\"expected\", \"missing\"]].sum().reset_index()\n",
    "    gb = pd.merge(gb, total, on=\"generator\", suffixes=(\"\", \" total\"))\n",
    "    gb[\"ratio missing (by generator)\"] = gb[\"missing\"] / gb[\"missing total\"]\n",
    "    gb[\"ratio missing (by generator)\"] = gb[\"ratio missing (by generator)\"].apply(lambda x: round(x, 4))\n",
    "    gb = gb.loc[:, ~gb.columns.str.contains(\"total\")]  # get rid of the total columns\n",
    "    gb.set_index([\"generator\", \"error\"], inplace=True)\n",
    "    gb.to_csv(os.path.join(out_fldr, \"missing_table.csv\"), index=False, mode=\"w\")\n",
    "else:\n",
    "    gb = None\n",
    "gb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.105564Z",
     "start_time": "2025-05-01T19:44:52.102637Z"
    }
   },
   "id": "3abe705ab17fdd17",
   "outputs": [],
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "source": [
    "for gen in generators:\n",
    "    masks = {\n",
    "        0: -1e20 > df_map[gen][\"lpBound\"],\n",
    "        1: df_map[gen][\"lpBound\"] - 1e-3 > df_map[gen][\"lpBoundPostVpc\"],\n",
    "        2: (df_map[gen][\"lpBoundPostVpc\"] - 1e-3 > df_map[gen][\"disjunctiveDualBound\"]) & ((gen == \"None\") | (gen == \"New\")),\n",
    "        3: df_map[gen][\"rootDualBound\"] - 1e-3 > df_map[gen][\"dualBound\"],\n",
    "        4: (df_map[gen][\"dualBound\"] - 1e-3 > df_map[gen][\"primalBound\"]) & (df_map[gen][\"dualBound\"] / df_map[gen][\"primalBound\"] > 1 + 1e-3),\n",
    "        5: df_map[gen][\"primalBound\"] > 1e20,\n",
    "        6: 0 > df_map[gen][\"vpcGenerationTime\"],\n",
    "        7: df_map[gen][\"vpcGenerationTime\"] - 1e-3 > df_map[gen][\"rootDualBoundTime\"],\n",
    "        8: df_map[gen][\"rootDualBoundTime\"] - 1e-3 > df_map[gen][\"terminationTime\"],\n",
    "        9: df_map[gen][\"vpcGenerationTime\"] - 1e-3 > df_map[gen][\"bestSolutionTime\"],\n",
    "        10: df_map[gen][\"bestSolutionTime\"] - 1e-3 > df_map[gen][\"terminationTime\"]\n",
    "    }\n",
    "    for i, mask in masks.items():\n",
    "        print(f\"{gen} {i}: {mask.sum() / len(df_map[gen])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.174368Z",
     "start_time": "2025-05-01T19:44:52.164466Z"
    }
   },
   "id": "1707d3125161409b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0: 0.0\n",
      "None 1: 0.0\n",
      "None 2: 0.0\n",
      "None 3: 0.0\n",
      "None 4: 0.0\n",
      "None 5: 0.0\n",
      "None 6: 0.0\n",
      "None 7: 0.0\n",
      "None 8: 0.0\n",
      "None 9: 0.0\n",
      "None 10: 0.0\n",
      "New 0: 0.0\n",
      "New 1: 0.0\n",
      "New 2: 0.0\n",
      "New 3: 0.0\n",
      "New 4: 0.0\n",
      "New 5: 0.0\n",
      "New 6: 0.0\n",
      "New 7: 0.0\n",
      "New 8: 0.0\n",
      "New 9: 0.0\n",
      "New 10: 0.0\n",
      "Farkas 0: 0.0\n",
      "Farkas 1: 0.0\n",
      "Farkas 2: 0.0\n",
      "Farkas 3: 0.0\n",
      "Farkas 4: 0.0\n",
      "Farkas 5: 0.0\n",
      "Farkas 6: 0.0\n",
      "Farkas 7: 0.0\n",
      "Farkas 8: 0.0\n",
      "Farkas 9: 0.0\n",
      "Farkas 10: 0.0\n",
      "All 0: 0.0\n",
      "All 1: 0.0\n",
      "All 2: 0.0\n",
      "All 3: 0.0\n",
      "All 4: 0.0\n",
      "All 5: 0.0\n",
      "All 6: 0.0\n",
      "All 7: 0.0\n",
      "All 8: 0.0\n",
      "All 9: 0.0\n",
      "All 10: 0.0\n",
      "NoDisjunction 0: 0.0\n",
      "NoDisjunction 1: 0.0\n",
      "NoDisjunction 2: 0.0\n",
      "NoDisjunction 3: 0.0\n",
      "NoDisjunction 4: 0.0\n",
      "NoDisjunction 5: 0.0\n",
      "NoDisjunction 6: 0.0\n",
      "NoDisjunction 7: 0.0\n",
      "NoDisjunction 8: 0.0\n",
      "NoDisjunction 9: 0.0\n",
      "NoDisjunction 10: 0.0\n",
      "NoMatrix 0: 0.0\n",
      "NoMatrix 1: 0.0\n",
      "NoMatrix 2: 0.0\n",
      "NoMatrix 3: 0.0\n",
      "NoMatrix 4: 0.0\n",
      "NoMatrix 5: 0.0\n",
      "NoMatrix 6: 0.0\n",
      "NoMatrix 7: 0.0\n",
      "NoMatrix 8: 0.0\n",
      "NoMatrix 9: 0.0\n",
      "NoMatrix 10: 0.0\n",
      "NoTerm 0: 0.0\n",
      "NoTerm 1: 0.0\n",
      "NoTerm 2: 0.0\n",
      "NoTerm 3: 0.0\n",
      "NoTerm 4: 0.0\n",
      "NoTerm 5: 0.0\n",
      "NoTerm 6: 0.0\n",
      "NoTerm 7: 0.0\n",
      "NoTerm 8: 0.0\n",
      "NoTerm 9: 0.0\n",
      "NoTerm 10: 0.0\n",
      "NoBasis 0: 0.0\n",
      "NoBasis 1: 0.0\n",
      "NoBasis 2: 0.0\n",
      "NoBasis 3: 0.0\n",
      "NoBasis 4: 0.0\n",
      "NoBasis 5: 0.0\n",
      "NoBasis 6: 0.0\n",
      "NoBasis 7: 0.0\n",
      "NoBasis 8: 0.0\n",
      "NoBasis 9: 0.0\n",
      "NoBasis 10: 0.0\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "cell_type": "code",
   "source": [
    "# it shouldn't be possible that dual bound > primal bound. this only happens when we use the saved primal bound, which was used to set the dual bound\n",
    "df_map[\"Farkas\"][masks[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.236019Z",
     "start_time": "2025-05-01T19:44:52.231588Z"
    }
   },
   "id": "4103872f43233ad8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [instanceIndex, seedIndex, vpcGenerator, terms, lpBound, disjunctiveDualBound, lpBoundPostVpc, rootDualBound, dualBound, primalBound, vpcGenerationTime, rootDualBoundTime, bestSolutionTime, terminationTime, nodes, iterations, maxTime, actualTerms, numCuts, cutLimit, mipSolver, providePrimalBound, infeasibleTerms, feasibleToInfeasibleTerms, infeasibleToFeasibleTerms, termRemainsFeasibleBasisInfeasible, cutsChangedCoefficients, feasibleTermsPrunedByBound, tighten_disjunction, tighten_matrix_perturbation, tighten_infeasible_to_feasible_term, tighten_feasible_to_infeasible_basis, instance, perturbation, degree, rows, cols, density]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 38 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceIndex</th>\n",
       "      <th>seedIndex</th>\n",
       "      <th>vpcGenerator</th>\n",
       "      <th>terms</th>\n",
       "      <th>lpBound</th>\n",
       "      <th>disjunctiveDualBound</th>\n",
       "      <th>lpBoundPostVpc</th>\n",
       "      <th>rootDualBound</th>\n",
       "      <th>dualBound</th>\n",
       "      <th>primalBound</th>\n",
       "      <th>...</th>\n",
       "      <th>tighten_disjunction</th>\n",
       "      <th>tighten_matrix_perturbation</th>\n",
       "      <th>tighten_infeasible_to_feasible_term</th>\n",
       "      <th>tighten_feasible_to_infeasible_basis</th>\n",
       "      <th>instance</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>degree</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  38 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 206
  },
  {
   "cell_type": "code",
   "source": [
    "for gen in df_map:\n",
    "    mask = (-1e20 > df_map[gen][\"lpBound\"]) | \\\n",
    "        (df_map[gen][\"lpBound\"] - 1e-3 > df_map[gen][\"lpBoundPostVpc\"]) | \\\n",
    "        ((df_map[gen][\"lpBoundPostVpc\"] - 1e-3 > df_map[gen][\"disjunctiveDualBound\"]) & (gen != \"Farkas\")) | \\\n",
    "        (df_map[gen][\"rootDualBound\"] - 1e-3 > df_map[gen][\"dualBound\"]) | \\\n",
    "        ((df_map[gen][\"dualBound\"] - 1e-3 > df_map[gen][\"primalBound\"]) & (df_map[gen][\"dualBound\"] / df_map[gen][\"primalBound\"] > 1 + 1e-3)) | \\\n",
    "        (df_map[gen][\"primalBound\"] > 1e20) | \\\n",
    "        (0 > df_map[gen][\"vpcGenerationTime\"]) | \\\n",
    "        (df_map[gen][\"vpcGenerationTime\"] - 1e-3 > df_map[gen][\"rootDualBoundTime\"]) | \\\n",
    "        (df_map[gen][\"rootDualBoundTime\"] - 1e-3 > df_map[gen][\"terminationTime\"]) | \\\n",
    "        (df_map[gen][\"vpcGenerationTime\"] - 1e-3 > df_map[gen][\"bestSolutionTime\"]) | \\\n",
    "        (df_map[gen][\"bestSolutionTime\"] - 1e-3 > df_map[gen][\"terminationTime\"])\n",
    "    print(f\"{gen}: {mask.sum() / len(df_map[gen])}\")\n",
    "    df_map[gen] = df_map[gen][~mask]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.357544Z",
     "start_time": "2025-05-01T19:44:52.345354Z"
    }
   },
   "id": "a9109f5e39680bda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 0.0\n",
      "Farkas: 0.0\n",
      "New: 0.0\n",
      "All: 0.0\n",
      "NoDisjunction: 0.0\n",
      "NoMatrix: 0.0\n",
      "NoTerm: 0.0\n",
      "NoBasis: 0.0\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "source": [
    "# merge the 4 different data frames into one\n",
    "join_cols = [\"instance\", \"perturbation\", \"degree\", \"terms\", \"instanceIndex\", \"seedIndex\"]\n",
    "df = df_map[\"None\"].merge(df_map[\"New\"], on=join_cols, suffixes=(\" None\", None))\n",
    "df = df.merge(df_map[\"Farkas\"], on=join_cols, suffixes=(\" New\", None))\n",
    "df = df.merge(df_map[\"All\"], on=join_cols, suffixes=(\" Farkas\", None))\n",
    "df = df.merge(df_map[\"NoDisjunction\"], on=join_cols, suffixes=(\" All\", None))\n",
    "df = df.merge(df_map[\"NoMatrix\"], on=join_cols, suffixes=(\" NoDisjunction\", None))\n",
    "df = df.merge(df_map[\"NoTerm\"], on=join_cols, suffixes=(\" NoMatrix\", None))\n",
    "df = df.merge(df_map[\"NoBasis\"], on=join_cols, suffixes=(\" NoTerm\", \" NoBasis\"))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.456560Z",
     "start_time": "2025-05-01T19:44:52.441145Z"
    }
   },
   "id": "66dfd7e3d44a3585",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   instanceIndex  seedIndex vpcGenerator None  terms  lpBound None  \\\n",
       "0              0          0              None     64     20.570922   \n",
       "1             10          0              None     64     20.661706   \n",
       "2             11          0              None     64     20.570922   \n",
       "3             12          0              None     64     20.077726   \n",
       "4             15          0              None     64     20.570922   \n",
       "\n",
       "   disjunctiveDualBound None  lpBoundPostVpc None  rootDualBound None  \\\n",
       "0                  20.570922            20.570922           26.427088   \n",
       "1                  20.661706            20.661706           25.938525   \n",
       "2                  20.570922            20.570922           26.427088   \n",
       "3                  20.077726            20.077726           25.242914   \n",
       "4                  20.570922            20.570922           26.427088   \n",
       "\n",
       "   dualBound None  primalBound None  ...  \\\n",
       "0            34.0              34.0  ...   \n",
       "1            34.0              34.0  ...   \n",
       "2            34.0              34.0  ...   \n",
       "3            33.0              33.0  ...   \n",
       "4            34.0              34.0  ...   \n",
       "\n",
       "   termRemainsFeasibleBasisInfeasible NoBasis  \\\n",
       "0                                           0   \n",
       "1                                           4   \n",
       "2                                           7   \n",
       "3                                           6   \n",
       "4                                           0   \n",
       "\n",
       "   cutsChangedCoefficients NoBasis  feasibleTermsPrunedByBound NoBasis  \\\n",
       "0                                0                                   0   \n",
       "1                                0                                  34   \n",
       "2                                0                                  32   \n",
       "3                                0                                  30   \n",
       "4                                0                                  32   \n",
       "\n",
       "   tighten_disjunction NoBasis  tighten_matrix_perturbation NoBasis  \\\n",
       "0                            0                                    0   \n",
       "1                            1                                    1   \n",
       "2                            1                                    1   \n",
       "3                            1                                    1   \n",
       "4                            1                                    1   \n",
       "\n",
       "   tighten_infeasible_to_feasible_term NoBasis  \\\n",
       "0                                            0   \n",
       "1                                            1   \n",
       "2                                            1   \n",
       "3                                            1   \n",
       "4                                            1   \n",
       "\n",
       "   tighten_feasible_to_infeasible_basis NoBasis  rows NoBasis  cols NoBasis  \\\n",
       "0                                             0            20            27   \n",
       "1                                             0            20            27   \n",
       "2                                             0            20            27   \n",
       "3                                             0            20            27   \n",
       "4                                             0            20            27   \n",
       "\n",
       "   density NoBasis  \n",
       "0         0.885185  \n",
       "1         0.885185  \n",
       "2         0.885185  \n",
       "3         0.885185  \n",
       "4         0.885185  \n",
       "\n",
       "[5 rows x 262 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceIndex</th>\n",
       "      <th>seedIndex</th>\n",
       "      <th>vpcGenerator None</th>\n",
       "      <th>terms</th>\n",
       "      <th>lpBound None</th>\n",
       "      <th>disjunctiveDualBound None</th>\n",
       "      <th>lpBoundPostVpc None</th>\n",
       "      <th>rootDualBound None</th>\n",
       "      <th>dualBound None</th>\n",
       "      <th>primalBound None</th>\n",
       "      <th>...</th>\n",
       "      <th>termRemainsFeasibleBasisInfeasible NoBasis</th>\n",
       "      <th>cutsChangedCoefficients NoBasis</th>\n",
       "      <th>feasibleTermsPrunedByBound NoBasis</th>\n",
       "      <th>tighten_disjunction NoBasis</th>\n",
       "      <th>tighten_matrix_perturbation NoBasis</th>\n",
       "      <th>tighten_infeasible_to_feasible_term NoBasis</th>\n",
       "      <th>tighten_feasible_to_infeasible_basis NoBasis</th>\n",
       "      <th>rows NoBasis</th>\n",
       "      <th>cols NoBasis</th>\n",
       "      <th>density NoBasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.885185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>25.938525</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.885185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.885185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>25.242914</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.885185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.885185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  262 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "source": [
    "# get proportion of tests run to completion\n",
    "4 * len(df) / count_instances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.554673Z",
     "start_time": "2025-05-01T19:44:52.552234Z"
    }
   },
   "id": "3eb13128df183faf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43915343915343913"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "source": [
    "def gap_closed(df, col):\n",
    "    gap = abs(df[col] - df[\"lpBound None\"]) / abs(df['primalBound None'] - df[\"lpBound None\"])\n",
    "    gap[(gap > 1) | (gap == np.nan)] = 1  # get corner cases\n",
    "    return gap\n",
    "\n",
    "# Function to map values based on a dictionary\n",
    "def check_same_solution(row):\n",
    "    # Create a tuple of the key based on the key_columns\n",
    "    return same_solution[row[\"perturbation\"], int(math.log2(row[\"degree\"])), f'{row[\"instance\"]}_{row[\"instanceIndex\"]}']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.647133Z",
     "start_time": "2025-05-01T19:44:52.644690Z"
    }
   },
   "id": "184a7a72592a8126",
   "outputs": [],
   "execution_count": 210
  },
  {
   "cell_type": "code",
   "source": [
    "# find the optimality gap closed by each generator\n",
    "df[\"Disjunction (New)\"] = gap_closed(df, \"disjunctiveDualBound New\")\n",
    "df[\"VPCs (New)\"] = gap_closed(df, \"lpBoundPostVpc New\")\n",
    "df[\"VPCs (Farkas)\"] = gap_closed(df, \"lpBoundPostVpc Farkas\")\n",
    "df[\"VPCs (All)\"] = gap_closed(df, \"lpBoundPostVpc All\")\n",
    "df[\"VPCs (NoDisjunction)\"] = gap_closed(df, \"lpBoundPostVpc NoDisjunction\")\n",
    "df[\"VPCs (NoMatrix)\"] = gap_closed(df, \"lpBoundPostVpc NoMatrix\")\n",
    "df[\"VPCs (NoTerm)\"] = gap_closed(df, \"lpBoundPostVpc NoTerm\")\n",
    "df[\"VPCs (NoBasis)\"] = gap_closed(df, \"lpBoundPostVpc NoBasis\")\n",
    "df[\"Root Cuts (None)\"] = gap_closed(df, \"rootDualBound None\")\n",
    "df[\"Root Cuts (New)\"] = gap_closed(df, \"rootDualBound New\")\n",
    "df[\"Root Cuts (Farkas)\"] = gap_closed(df, \"rootDualBound Farkas\")\n",
    "df[\"Root Cuts (All)\"] = gap_closed(df, \"rootDualBound All\")\n",
    "df[\"Root Cuts (NoDisjunction)\"] = gap_closed(df, \"rootDualBound NoDisjunction\")\n",
    "df[\"Root Cuts (NoMatrix)\"] = gap_closed(df, \"rootDualBound NoMatrix\")\n",
    "df[\"Root Cuts (NoTerm)\"] = gap_closed(df, \"rootDualBound NoTerm\")\n",
    "df[\"Root Cuts (NoBasis)\"] = gap_closed(df, \"rootDualBound NoBasis\")\n",
    "df[\"Root Optimality Gap Improvement\"] = df[\"Root Cuts (Farkas)\"] - df[\"Root Cuts (None)\"] \n",
    "# df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.802739Z",
     "start_time": "2025-05-01T19:44:52.793221Z"
    }
   },
   "id": "2e64c92d6bbd14b9",
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "source": [
    "# find times without vpc generation\n",
    "df[\"terminationTimeSansVpc None\"] = df[\"terminationTime None\"]\n",
    "df[\"rootDualBoundTimeSansVpc None\"] = df[\"rootDualBoundTime None\"]\n",
    "for gen in generators:\n",
    "    if gen != \"None\":\n",
    "        df[f\"terminationTimeSansVpc {gen}\"] = df[f\"terminationTime {gen}\"] - df[\"vpcGenerationTime New\"]\n",
    "        df[f\"rootDualBoundTimeSansVpc {gen}\"] = df[f\"rootDualBoundTime {gen}\"] - df[f\"vpcGenerationTime {gen}\"]\n",
    "    df[f\"postRootTime {gen}\"] = df[f\"terminationTime {gen}\"] - df[f\"rootDualBoundTime {gen}\"]\n",
    "    if gen not in [\"None\", \"New\"]:\n",
    "        df[f\"terminationTimeImprovement {gen}\"] = (df[\"terminationTime None\"] - df[f\"terminationTime {gen}\"]) / df[\"terminationTime None\"]\n",
    "        df[f\"terminationTimeSansVpcImprovement {gen}\"] = (df[\"terminationTimeSansVpc None\"] - df[f\"terminationTimeSansVpc {gen}\"]) / df[\"terminationTimeSansVpc None\"]\n",
    "        df[f\"nodesImprovement {gen}\"] = (df[\"nodes None\"] - df[f\"nodes {gen}\"]) / df[\"nodes None\"] \n",
    "        df[f\"iterationsImprovement {gen}\"] = (df[\"iterations None\"] - df[f\"iterations {gen}\"]) / df[\"iterations None\"] \n",
    "        df[f\"terminationTimeRatio {gen}\"] = df[f\"terminationTime {gen}\"] / df[\"terminationTime None\"]\n",
    "        df[f\"terminationTimeSansVpcRatio {gen}\"] = df[f\"terminationTimeSansVpc {gen}\"] / df[\"terminationTimeSansVpc None\"]\n",
    "        df[f\"nodesRatio {gen}\"] = df[f\"nodes {gen}\"] / df[\"nodes None\"] \n",
    "        df[f\"iterationsRatio {gen}\"] = df[f\"iterations {gen}\"] / df[\"iterations None\"]\n",
    "        df[f\"nodesImproves {gen}\"] = df[\"nodes None\"] > df[f\"nodes {gen}\"]\n",
    "        df[f\"terminationTimeImproves {gen}\"] = df[\"terminationTime None\"] > df[f\"terminationTime {gen}\"]\n",
    "        df[f\"terminationTimeSansVpcImproves {gen}\"] = df[\"terminationTimeSansVpc None\"] > df[f\"terminationTimeSansVpc {gen}\"]\n",
    "        df[f\"iterationsImproves {gen}\"] = df[\"iterations None\"] > df[f\"iterations {gen}\"]\n",
    "        df[f'nodesWin{gen}'] = df['nodes None']*(1 - win_threshold) > df[f'nodes {gen}']\n",
    "        df[f'terminationTimeWin{gen}'] = df['terminationTime None']*(1 - win_threshold) > df[f'terminationTime {gen}']\n",
    "        df[f'terminationTimeSansVpcWin{gen}'] = df['terminationTimeSansVpc None']*(1 - win_threshold) > df[f'terminationTimeSansVpc {gen}']\n",
    "        df[f'iterationsWin{gen}'] = df['iterations None']*(1 - win_threshold) > df[f'iterations {gen}']\n",
    "        df[f'nodesWinNoneVs{gen}'] = df[f'nodes {gen}']*(1 - win_threshold) > df['nodes None']\n",
    "        df[f'terminationTimeWinNoneVs{gen}'] = df[f'terminationTime {gen}']*(1 - win_threshold) > df['terminationTime None']\n",
    "        df[f'terminationTimeSansVpcWinNoneVs{gen}'] = df[f'terminationTimeSansVpc {gen}']*(1 - win_threshold) > df['terminationTimeSansVpc None']\n",
    "        df[f'iterationsWinNoneVs{gen}'] = df[f'iterations {gen}']*(1 - win_threshold) > df['iterations None']\n",
    "df[\"bracket\"] = [\"short\" if t <= short else \"medium\" if t <= medium else \"long\" for t in df[\"terminationTime None\"]]\n",
    "df[\"sameSolution\"] = df.apply(check_same_solution, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:52.907374Z",
     "start_time": "2025-05-01T19:44:52.876834Z"
    }
   },
   "id": "b4ee3b9fd2d34abf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeRatio {gen}\"] = df[f\"terminationTime {gen}\"] / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcRatio {gen}\"] = df[f\"terminationTimeSansVpc {gen}\"] / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesRatio {gen}\"] = df[f\"nodes {gen}\"] / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsRatio {gen}\"] = df[f\"iterations {gen}\"] / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImproves {gen}\"] = df[\"nodes None\"] > df[f\"nodes {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImproves {gen}\"] = df[\"terminationTime None\"] > df[f\"terminationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImproves {gen}\"] = df[\"terminationTimeSansVpc None\"] > df[f\"terminationTimeSansVpc {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImproves {gen}\"] = df[\"iterations None\"] > df[f\"iterations {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWin{gen}'] = df['nodes None']*(1 - win_threshold) > df[f'nodes {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWin{gen}'] = df['terminationTime None']*(1 - win_threshold) > df[f'terminationTime {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWin{gen}'] = df['terminationTimeSansVpc None']*(1 - win_threshold) > df[f'terminationTimeSansVpc {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWin{gen}'] = df['iterations None']*(1 - win_threshold) > df[f'iterations {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWinNoneVs{gen}'] = df[f'nodes {gen}']*(1 - win_threshold) > df['nodes None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWinNoneVs{gen}'] = df[f'terminationTime {gen}']*(1 - win_threshold) > df['terminationTime None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWinNoneVs{gen}'] = df[f'terminationTimeSansVpc {gen}']*(1 - win_threshold) > df['terminationTimeSansVpc None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWinNoneVs{gen}'] = df[f'iterations {gen}']*(1 - win_threshold) > df['iterations None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpc {gen}\"] = df[f\"terminationTime {gen}\"] - df[\"vpcGenerationTime New\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rootDualBoundTimeSansVpc {gen}\"] = df[f\"rootDualBoundTime {gen}\"] - df[f\"vpcGenerationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"postRootTime {gen}\"] = df[f\"terminationTime {gen}\"] - df[f\"rootDualBoundTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImprovement {gen}\"] = (df[\"terminationTime None\"] - df[f\"terminationTime {gen}\"]) / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImprovement {gen}\"] = (df[\"terminationTimeSansVpc None\"] - df[f\"terminationTimeSansVpc {gen}\"]) / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImprovement {gen}\"] = (df[\"nodes None\"] - df[f\"nodes {gen}\"]) / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImprovement {gen}\"] = (df[\"iterations None\"] - df[f\"iterations {gen}\"]) / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeRatio {gen}\"] = df[f\"terminationTime {gen}\"] / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcRatio {gen}\"] = df[f\"terminationTimeSansVpc {gen}\"] / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesRatio {gen}\"] = df[f\"nodes {gen}\"] / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsRatio {gen}\"] = df[f\"iterations {gen}\"] / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImproves {gen}\"] = df[\"nodes None\"] > df[f\"nodes {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImproves {gen}\"] = df[\"terminationTime None\"] > df[f\"terminationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImproves {gen}\"] = df[\"terminationTimeSansVpc None\"] > df[f\"terminationTimeSansVpc {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImproves {gen}\"] = df[\"iterations None\"] > df[f\"iterations {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWin{gen}'] = df['nodes None']*(1 - win_threshold) > df[f'nodes {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWin{gen}'] = df['terminationTime None']*(1 - win_threshold) > df[f'terminationTime {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWin{gen}'] = df['terminationTimeSansVpc None']*(1 - win_threshold) > df[f'terminationTimeSansVpc {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWin{gen}'] = df['iterations None']*(1 - win_threshold) > df[f'iterations {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWinNoneVs{gen}'] = df[f'nodes {gen}']*(1 - win_threshold) > df['nodes None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWinNoneVs{gen}'] = df[f'terminationTime {gen}']*(1 - win_threshold) > df['terminationTime None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWinNoneVs{gen}'] = df[f'terminationTimeSansVpc {gen}']*(1 - win_threshold) > df['terminationTimeSansVpc None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWinNoneVs{gen}'] = df[f'iterations {gen}']*(1 - win_threshold) > df['iterations None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpc {gen}\"] = df[f\"terminationTime {gen}\"] - df[\"vpcGenerationTime New\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rootDualBoundTimeSansVpc {gen}\"] = df[f\"rootDualBoundTime {gen}\"] - df[f\"vpcGenerationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"postRootTime {gen}\"] = df[f\"terminationTime {gen}\"] - df[f\"rootDualBoundTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImprovement {gen}\"] = (df[\"terminationTime None\"] - df[f\"terminationTime {gen}\"]) / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImprovement {gen}\"] = (df[\"terminationTimeSansVpc None\"] - df[f\"terminationTimeSansVpc {gen}\"]) / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImprovement {gen}\"] = (df[\"nodes None\"] - df[f\"nodes {gen}\"]) / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImprovement {gen}\"] = (df[\"iterations None\"] - df[f\"iterations {gen}\"]) / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeRatio {gen}\"] = df[f\"terminationTime {gen}\"] / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcRatio {gen}\"] = df[f\"terminationTimeSansVpc {gen}\"] / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesRatio {gen}\"] = df[f\"nodes {gen}\"] / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsRatio {gen}\"] = df[f\"iterations {gen}\"] / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImproves {gen}\"] = df[\"nodes None\"] > df[f\"nodes {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImproves {gen}\"] = df[\"terminationTime None\"] > df[f\"terminationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImproves {gen}\"] = df[\"terminationTimeSansVpc None\"] > df[f\"terminationTimeSansVpc {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImproves {gen}\"] = df[\"iterations None\"] > df[f\"iterations {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWin{gen}'] = df['nodes None']*(1 - win_threshold) > df[f'nodes {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWin{gen}'] = df['terminationTime None']*(1 - win_threshold) > df[f'terminationTime {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWin{gen}'] = df['terminationTimeSansVpc None']*(1 - win_threshold) > df[f'terminationTimeSansVpc {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWin{gen}'] = df['iterations None']*(1 - win_threshold) > df[f'iterations {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWinNoneVs{gen}'] = df[f'nodes {gen}']*(1 - win_threshold) > df['nodes None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWinNoneVs{gen}'] = df[f'terminationTime {gen}']*(1 - win_threshold) > df['terminationTime None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWinNoneVs{gen}'] = df[f'terminationTimeSansVpc {gen}']*(1 - win_threshold) > df['terminationTimeSansVpc None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWinNoneVs{gen}'] = df[f'iterations {gen}']*(1 - win_threshold) > df['iterations None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpc {gen}\"] = df[f\"terminationTime {gen}\"] - df[\"vpcGenerationTime New\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rootDualBoundTimeSansVpc {gen}\"] = df[f\"rootDualBoundTime {gen}\"] - df[f\"vpcGenerationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"postRootTime {gen}\"] = df[f\"terminationTime {gen}\"] - df[f\"rootDualBoundTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImprovement {gen}\"] = (df[\"terminationTime None\"] - df[f\"terminationTime {gen}\"]) / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImprovement {gen}\"] = (df[\"terminationTimeSansVpc None\"] - df[f\"terminationTimeSansVpc {gen}\"]) / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImprovement {gen}\"] = (df[\"nodes None\"] - df[f\"nodes {gen}\"]) / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImprovement {gen}\"] = (df[\"iterations None\"] - df[f\"iterations {gen}\"]) / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeRatio {gen}\"] = df[f\"terminationTime {gen}\"] / df[\"terminationTime None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcRatio {gen}\"] = df[f\"terminationTimeSansVpc {gen}\"] / df[\"terminationTimeSansVpc None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesRatio {gen}\"] = df[f\"nodes {gen}\"] / df[\"nodes None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsRatio {gen}\"] = df[f\"iterations {gen}\"] / df[\"iterations None\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"nodesImproves {gen}\"] = df[\"nodes None\"] > df[f\"nodes {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeImproves {gen}\"] = df[\"terminationTime None\"] > df[f\"terminationTime {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"terminationTimeSansVpcImproves {gen}\"] = df[\"terminationTimeSansVpc None\"] > df[f\"terminationTimeSansVpc {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"iterationsImproves {gen}\"] = df[\"iterations None\"] > df[f\"iterations {gen}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWin{gen}'] = df['nodes None']*(1 - win_threshold) > df[f'nodes {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWin{gen}'] = df['terminationTime None']*(1 - win_threshold) > df[f'terminationTime {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWin{gen}'] = df['terminationTimeSansVpc None']*(1 - win_threshold) > df[f'terminationTimeSansVpc {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWin{gen}'] = df['iterations None']*(1 - win_threshold) > df[f'iterations {gen}']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'nodesWinNoneVs{gen}'] = df[f'nodes {gen}']*(1 - win_threshold) > df['nodes None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeWinNoneVs{gen}'] = df[f'terminationTime {gen}']*(1 - win_threshold) > df['terminationTime None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'terminationTimeSansVpcWinNoneVs{gen}'] = df[f'terminationTimeSansVpc {gen}']*(1 - win_threshold) > df['terminationTimeSansVpc None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'iterationsWinNoneVs{gen}'] = df[f'iterations {gen}']*(1 - win_threshold) > df['iterations None']\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"bracket\"] = [\"short\" if t <= short else \"medium\" if t <= medium else \"long\" for t in df[\"terminationTime None\"]]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/3168479867.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"sameSolution\"] = df.apply(check_same_solution, axis=1)\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "source": [
    "# get sensitivity stats as ratios\n",
    "for gen_name in generators:\n",
    "    if gen_name == \"None\":\n",
    "        continue\n",
    "    df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
    "    df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
    "    df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
    "    df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:53.060514Z",
     "start_time": "2025-05-01T19:44:53.053530Z"
    }
   },
   "id": "d7bf06fb128ade6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"infeasibleToFeasibleTermsRatio {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"zeroInfeasibleToFeasibleTerms {gen_name}\"] = df[f\"infeasibleToFeasibleTerms {gen_name}\"] == 0\n",
      "/var/folders/pb/p1sshdnx5sv12zwsxff8nrg40000gn/T/ipykernel_96082/393337708.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"feasibleToInfeasibleTermsRatio {gen_name}\"] = df[f\"feasibleToInfeasibleTerms {gen_name}\"] / df[f\"actualTerms {gen_name}\"]\n"
     ]
    }
   ],
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "source": [
    "def optimality_gap(df, generator=None):\n",
    "    if generator:\n",
    "        return abs(df[f\"primalBound {generator}\"] - df[f\"dualBound {generator}\"]) / \\\n",
    "            abs(df[f\"primalBound {generator}\"])\n",
    "    else:\n",
    "        return abs(df[f\"primalBound\"] - df[f\"dualBound\"]) / abs(df[f\"primalBound\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:53.240107Z",
     "start_time": "2025-05-01T19:44:53.237475Z"
    }
   },
   "id": "5e06417f22452766",
   "outputs": [],
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "source": [
    "# aleks filters\n",
    "# df = df.loc[df[\"terms\"] == df[\"actualTerms Farkas\"]]\n",
    "# df = df.loc[df[\"zeroInfeasibleToFeasibleTerms Farkas\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:53.491650Z",
     "start_time": "2025-05-01T19:44:53.489987Z"
    }
   },
   "id": "ec90a15cca2ab140",
   "outputs": [],
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "source": "df.head()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:53.737476Z",
     "start_time": "2025-05-01T19:44:53.728275Z"
    }
   },
   "id": "55a07f7fdbf31995",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   instanceIndex  seedIndex vpcGenerator None  terms  lpBound None  \\\n",
       "0              0          0              None     64     20.570922   \n",
       "1             10          0              None     64     20.661706   \n",
       "2             11          0              None     64     20.570922   \n",
       "3             12          0              None     64     20.077726   \n",
       "4             15          0              None     64     20.570922   \n",
       "\n",
       "   disjunctiveDualBound None  lpBoundPostVpc None  rootDualBound None  \\\n",
       "0                  20.570922            20.570922           26.427088   \n",
       "1                  20.661706            20.661706           25.938525   \n",
       "2                  20.570922            20.570922           26.427088   \n",
       "3                  20.077726            20.077726           25.242914   \n",
       "4                  20.570922            20.570922           26.427088   \n",
       "\n",
       "   dualBound None  primalBound None  ...  \\\n",
       "0            34.0              34.0  ...   \n",
       "1            34.0              34.0  ...   \n",
       "2            34.0              34.0  ...   \n",
       "3            33.0              33.0  ...   \n",
       "4            34.0              34.0  ...   \n",
       "\n",
       "   zeroInfeasibleToFeasibleTerms NoMatrix  \\\n",
       "0                                    True   \n",
       "1                                    True   \n",
       "2                                    True   \n",
       "3                                    True   \n",
       "4                                    True   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoMatrix  infeasibleTermsRatio NoTerm  \\\n",
       "0                                 0.000000                     0.031250   \n",
       "1                                 0.015625                     0.046875   \n",
       "2                                 0.000000                     0.031250   \n",
       "3                                 0.000000                     0.031250   \n",
       "4                                 0.000000                     0.031250   \n",
       "\n",
       "   infeasibleToFeasibleTermsRatio NoTerm  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   zeroInfeasibleToFeasibleTerms NoTerm  \\\n",
       "0                                  True   \n",
       "1                                  True   \n",
       "2                                  True   \n",
       "3                                  True   \n",
       "4                                  True   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoTerm  infeasibleTermsRatio NoBasis  \\\n",
       "0                               0.000000                      0.031250   \n",
       "1                               0.015625                      0.046875   \n",
       "2                               0.000000                      0.031250   \n",
       "3                               0.000000                      0.031250   \n",
       "4                               0.000000                      0.031250   \n",
       "\n",
       "   infeasibleToFeasibleTermsRatio NoBasis  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   zeroInfeasibleToFeasibleTerms NoBasis  \\\n",
       "0                                   True   \n",
       "1                                   True   \n",
       "2                                   True   \n",
       "3                                   True   \n",
       "4                                   True   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoBasis  \n",
       "0                                0.000000  \n",
       "1                                0.015625  \n",
       "2                                0.000000  \n",
       "3                                0.000000  \n",
       "4                                0.000000  \n",
       "\n",
       "[5 rows x 453 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceIndex</th>\n",
       "      <th>seedIndex</th>\n",
       "      <th>vpcGenerator None</th>\n",
       "      <th>terms</th>\n",
       "      <th>lpBound None</th>\n",
       "      <th>disjunctiveDualBound None</th>\n",
       "      <th>lpBoundPostVpc None</th>\n",
       "      <th>rootDualBound None</th>\n",
       "      <th>dualBound None</th>\n",
       "      <th>primalBound None</th>\n",
       "      <th>...</th>\n",
       "      <th>zeroInfeasibleToFeasibleTerms NoMatrix</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoMatrix</th>\n",
       "      <th>infeasibleTermsRatio NoTerm</th>\n",
       "      <th>infeasibleToFeasibleTermsRatio NoTerm</th>\n",
       "      <th>zeroInfeasibleToFeasibleTerms NoTerm</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoTerm</th>\n",
       "      <th>infeasibleTermsRatio NoBasis</th>\n",
       "      <th>infeasibleToFeasibleTermsRatio NoBasis</th>\n",
       "      <th>zeroInfeasibleToFeasibleTerms NoBasis</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoBasis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>20.661706</td>\n",
       "      <td>25.938525</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>20.077726</td>\n",
       "      <td>25.242914</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>64</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>20.570922</td>\n",
       "      <td>26.427088</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  453 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:54.116095Z",
     "start_time": "2025-05-01T19:44:54.104611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set aside core columns and filter for all subsequent dataframes\n",
    "group_cols = [\"instance\", \"perturbation\", \"bracket\", \"degree\", \"terms\"]\n",
    "id_cols = [\"instanceIndex\"]\n",
    "\n",
    "# keep the instance, perturbation, instanceIndex triples that exist for all combinations of degree and terms\n",
    "# where VPC did not find the optimal solution\n",
    "full_df = df.loc[df[\"Disjunction (New)\"] < .9999]\n",
    "triples = (full_df.groupby(\n",
    "        [\"instance\", \"perturbation\", \"instanceIndex\"]\n",
    "    ).size().reset_index().rename(columns={0: \"count\"}))\n",
    "triples.head()"
   ],
   "id": "20e18b9d8d3b5b55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  instance perturbation  instanceIndex  count\n",
       "0     bm23       matrix              0      6\n",
       "1     bm23       matrix              1      6\n",
       "2     bm23       matrix              2      4\n",
       "3     bm23       matrix              3      5\n",
       "4     bm23       matrix              4      5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>instanceIndex</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm23</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm23</td>\n",
       "      <td>matrix</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm23</td>\n",
       "      <td>matrix</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm23</td>\n",
       "      <td>matrix</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bm23</td>\n",
       "      <td>matrix</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:54.389463Z",
     "start_time": "2025-05-01T19:44:54.338769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# uncomment to filter for only the triples that exist for all combinations of degree and terms (and seed index)\n",
    "# triples = triples[triples[\"count\"] == len(degrees) * len(term_list) * len(seed_idxs)]\n",
    "# full_df = full_df.merge(triples, on=[\"instance\", \"perturbation\", \"instanceIndex\"])\n",
    "full_df.to_csv(os.path.join(out_fldr, \"cleaned_combined_complete.csv\"), index=False, mode=\"w\")"
   ],
   "id": "fcff718d6277a172",
   "outputs": [],
   "execution_count": 218
  },
  {
   "cell_type": "markdown",
   "source": "## Check Root Node Stats",
   "metadata": {
    "collapsed": false
   },
   "id": "2f3bb4783d418904"
  },
  {
   "cell_type": "code",
   "source": [
    "def interleave(list_of_lists):\n",
    "    return [item for sublist in zip(*list_of_lists) for item in sublist]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:54.948107Z",
     "start_time": "2025-05-01T19:44:54.945987Z"
    }
   },
   "id": "dd68a9bcb789fb6e",
   "outputs": [],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "source": [
    "# additional filtering for dataframe on bounds\n",
    "fields = [\"Disjunction (New)\"] + [f\"VPCs ({gen_name})\" for gen_name in generators if gen_name != \"None\"] + \\\n",
    "    interleave([[f\"Root Cuts ({gen_name})\", f\"terminationTime {gen_name}\", f\"nodes {gen_name}\",\n",
    "                 f\"iterations {gen_name}\", f\"terminationTimeSansVpc {gen_name}\", f\"vpcGenerationTime {gen_name}\", \n",
    "                 f\"rootDualBoundTime {gen_name}\"]\n",
    "                for gen_name in generators]) + \\\n",
    "    interleave([[f\"infeasibleTermsRatio {gen_name}\", f\"infeasibleToFeasibleTermsRatio {gen_name}\",\n",
    "                 f\"zeroInfeasibleToFeasibleTerms {gen_name}\", f\"feasibleToInfeasibleTermsRatio {gen_name}\"]\n",
    "                for gen_name in generators if gen_name != \"None\"])\n",
    "\n",
    "# now reduce bound_df to just the perturbed instances - make > -1 to include base instance\n",
    "bound_df = full_df.loc[full_df[\"instanceIndex\"] > 0, group_cols + id_cols + fields]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:55.474844Z",
     "start_time": "2025-05-01T19:44:55.468973Z"
    }
   },
   "id": "1446af429a86e44f",
   "outputs": [],
   "execution_count": 220
  },
  {
   "cell_type": "code",
   "source": [
    "def geometric_mean(series, offset=1e-6):\n",
    "    adjusted_series = series + offset  # Add a small offset to avoid zeros\n",
    "    return np.exp(np.log(adjusted_series).mean())\n",
    "\n",
    "# paper currently uses mean, but we can switch to geometric mean if we want\n",
    "aggregations = {f: geometric_mean if f not in [\"sameSolution\"] else \"mean\" for f in fields}\n",
    "aggregations[\"instance\"] = \"nunique\"\n",
    "aggregations[\"instanceIndex\"] = \"count\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:55.876889Z",
     "start_time": "2025-05-01T19:44:55.874213Z"
    }
   },
   "id": "2e2bbc44b009d720",
   "outputs": [],
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "source": [
    "# get gap closed by degree and term\n",
    "out = bound_df.groupby([\"degree\", \"terms\"]).agg(aggregations).reset_index()\n",
    "out.to_csv(os.path.join(out_fldr, \"bound_table.csv\"), index=False, mode=\"w\")\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:56.293791Z",
     "start_time": "2025-05-01T19:44:56.223101Z"
    }
   },
   "id": "588a0ef9d23dad30",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/miniconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   degree  terms  Disjunction (New)  VPCs (New)  VPCs (Farkas)  VPCs (All)  \\\n",
       "0       1      4           0.140507    0.140292       0.144259    0.144310   \n",
       "1       1     64           0.679605    0.663024       0.494280    0.663293   \n",
       "2       4      4           0.111304    0.108766       0.078547    0.086747   \n",
       "3       4     64           0.663510    0.649138       0.017885    0.527745   \n",
       "4      16      4           0.114902    0.104119       0.000039    0.000065   \n",
       "5      16     64           0.545098    0.524853       0.000205    0.000638   \n",
       "\n",
       "   VPCs (NoDisjunction)  VPCs (NoMatrix)  VPCs (NoTerm)  VPCs (NoBasis)  ...  \\\n",
       "0              0.144310         0.144284       0.144310        0.144310  ...   \n",
       "1              0.652605         0.662717       0.663293        0.663018  ...   \n",
       "2              0.086583         0.084137       0.086747        0.086003  ...   \n",
       "3              0.478660         0.491125       0.527745        0.510831  ...   \n",
       "4              0.000065         0.000056       0.000065        0.000065  ...   \n",
       "5              0.000827         0.000471       0.000638        0.000638  ...   \n",
       "\n",
       "   zeroInfeasibleToFeasibleTerms NoBasis  feasibleToInfeasibleTermsRatio New  \\\n",
       "0                               1.000001                            0.000001   \n",
       "1                               1.000001                            0.000001   \n",
       "2                               1.000001                            0.000001   \n",
       "3                               0.501188                            0.000001   \n",
       "4                               1.000001                            0.000001   \n",
       "5                               0.021163                            0.000001   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio Farkas  feasibleToInfeasibleTermsRatio All  \\\n",
       "0                               0.000001                            0.000001   \n",
       "1                               0.000007                            0.000007   \n",
       "2                               0.000001                            0.000001   \n",
       "3                               0.000028                            0.000028   \n",
       "4                               0.000001                            0.000001   \n",
       "5                               0.000693                            0.000693   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoDisjunction  \\\n",
       "0                                      0.000001   \n",
       "1                                      0.000007   \n",
       "2                                      0.000001   \n",
       "3                                      0.000028   \n",
       "4                                      0.000001   \n",
       "5                                      0.000693   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoMatrix  \\\n",
       "0                                 0.000001   \n",
       "1                                 0.000007   \n",
       "2                                 0.000001   \n",
       "3                                 0.000028   \n",
       "4                                 0.000001   \n",
       "5                                 0.000693   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoTerm  \\\n",
       "0                               0.000001   \n",
       "1                               0.000007   \n",
       "2                               0.000001   \n",
       "3                               0.000028   \n",
       "4                               0.000001   \n",
       "5                               0.000693   \n",
       "\n",
       "   feasibleToInfeasibleTermsRatio NoBasis  instance  instanceIndex  \n",
       "0                                0.000001         1             60  \n",
       "1                                0.000007         1             51  \n",
       "2                                0.000001         1             60  \n",
       "3                                0.000028         1             40  \n",
       "4                                0.000001         1             60  \n",
       "5                                0.000693         1             43  \n",
       "\n",
       "[6 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>terms</th>\n",
       "      <th>Disjunction (New)</th>\n",
       "      <th>VPCs (New)</th>\n",
       "      <th>VPCs (Farkas)</th>\n",
       "      <th>VPCs (All)</th>\n",
       "      <th>VPCs (NoDisjunction)</th>\n",
       "      <th>VPCs (NoMatrix)</th>\n",
       "      <th>VPCs (NoTerm)</th>\n",
       "      <th>VPCs (NoBasis)</th>\n",
       "      <th>...</th>\n",
       "      <th>zeroInfeasibleToFeasibleTerms NoBasis</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio New</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio Farkas</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio All</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoDisjunction</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoMatrix</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoTerm</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoBasis</th>\n",
       "      <th>instance</th>\n",
       "      <th>instanceIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.140507</td>\n",
       "      <td>0.140292</td>\n",
       "      <td>0.144259</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>0.144284</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.679605</td>\n",
       "      <td>0.663024</td>\n",
       "      <td>0.494280</td>\n",
       "      <td>0.663293</td>\n",
       "      <td>0.652605</td>\n",
       "      <td>0.662717</td>\n",
       "      <td>0.663293</td>\n",
       "      <td>0.663018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111304</td>\n",
       "      <td>0.108766</td>\n",
       "      <td>0.078547</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>0.086583</td>\n",
       "      <td>0.084137</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>0.086003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.649138</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.527745</td>\n",
       "      <td>0.478660</td>\n",
       "      <td>0.491125</td>\n",
       "      <td>0.527745</td>\n",
       "      <td>0.510831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501188</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.114902</td>\n",
       "      <td>0.104119</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.524853</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  96 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "source": [
    "# now break it down by type of perturbation\n",
    "out = bound_df.groupby([\"degree\", \"terms\", \"perturbation\"]).agg(aggregations).reset_index()\n",
    "out.to_csv(os.path.join(out_fldr, \"bound_table_by_perturbation.csv\"), index=False, mode=\"w\")\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:56.773739Z",
     "start_time": "2025-05-01T19:44:56.631566Z"
    }
   },
   "id": "7c7dd20910d976da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/miniconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    degree  terms perturbation  Disjunction (New)  VPCs (New)  VPCs (Farkas)  \\\n",
       "0        1      4       matrix           0.139849    0.139849       0.142625   \n",
       "1        1      4    objective           0.146033    0.146033       0.146033   \n",
       "2        1      4          rhs           0.135827    0.135204       0.144141   \n",
       "3        1     64       matrix           0.683543    0.665729       0.579877   \n",
       "4        1     64    objective           0.665545    0.648594       0.686673   \n",
       "5        1     64          rhs           0.697293    0.683371       0.221915   \n",
       "6        4      4       matrix           0.101753    0.100893       0.081293   \n",
       "7        4      4    objective           0.135393    0.134473       0.135029   \n",
       "8        4      4          rhs           0.100090    0.094838       0.044148   \n",
       "9        4     64       matrix           0.650560    0.637210       0.000047   \n",
       "10       4     64    objective           0.657222    0.644646       0.638456   \n",
       "11       4     64          rhs           0.691134    0.672095       0.035999   \n",
       "12      16      4       matrix           0.118144    0.108274       0.000001   \n",
       "13      16      4    objective           0.110269    0.099879       0.023225   \n",
       "14      16      4          rhs           0.116445    0.104373       0.000002   \n",
       "15      16     64       matrix           0.588353    0.567842       0.000001   \n",
       "16      16     64    objective           0.586280    0.561469       0.332769   \n",
       "17      16     64          rhs           0.467465    0.452397       0.000001   \n",
       "\n",
       "    VPCs (All)  VPCs (NoDisjunction)  VPCs (NoMatrix)  VPCs (NoTerm)  ...  \\\n",
       "0     0.142776              0.142776         0.142699       0.142776  ...   \n",
       "1     0.146033              0.146033         0.146033       0.146033  ...   \n",
       "2     0.144141              0.144141         0.144141       0.144141  ...   \n",
       "3     0.631318              0.604382         0.629848       0.631318  ...   \n",
       "4     0.686673              0.686673         0.686673       0.686673  ...   \n",
       "5     0.677023              0.677023         0.677023       0.677023  ...   \n",
       "6     0.106711              0.106109         0.097366       0.106711  ...   \n",
       "7     0.135029              0.135029         0.135029       0.135029  ...   \n",
       "8     0.045303              0.045303         0.045303       0.045303  ...   \n",
       "9     0.386260              0.278970         0.303930       0.386260  ...   \n",
       "10    0.638456              0.638456         0.638456       0.638456  ...   \n",
       "11    0.544757              0.544757         0.544757       0.544757  ...   \n",
       "12    0.000007              0.000007         0.000004       0.000007  ...   \n",
       "13    0.023225              0.023225         0.023225       0.023225  ...   \n",
       "14    0.000002              0.000002         0.000002       0.000002  ...   \n",
       "15    0.000085              0.000234         0.000026       0.000085  ...   \n",
       "16    0.332769              0.332769         0.332769       0.332769  ...   \n",
       "17    0.000001              0.000001         0.000001       0.000001  ...   \n",
       "\n",
       "    zeroInfeasibleToFeasibleTerms NoBasis  feasibleToInfeasibleTermsRatio New  \\\n",
       "0                                1.000001                            0.000001   \n",
       "1                                1.000001                            0.000001   \n",
       "2                                1.000001                            0.000001   \n",
       "3                                1.000001                            0.000001   \n",
       "4                                1.000001                            0.000001   \n",
       "5                                1.000001                            0.000001   \n",
       "6                                1.000001                            0.000001   \n",
       "7                                1.000001                            0.000001   \n",
       "8                                1.000001                            0.000001   \n",
       "9                                0.100000                            0.000001   \n",
       "10                               1.000001                            0.000001   \n",
       "11                               1.000001                            0.000001   \n",
       "12                               1.000001                            0.000001   \n",
       "13                               1.000001                            0.000001   \n",
       "14                               1.000001                            0.000001   \n",
       "15                               0.000534                            0.000001   \n",
       "16                               1.000001                            0.000001   \n",
       "17                               0.002683                            0.000001   \n",
       "\n",
       "    feasibleToInfeasibleTermsRatio Farkas  feasibleToInfeasibleTermsRatio All  \\\n",
       "0                                0.000001                            0.000001   \n",
       "1                                0.000001                            0.000001   \n",
       "2                                0.000001                            0.000001   \n",
       "3                                0.000013                            0.000013   \n",
       "4                                0.000001                            0.000001   \n",
       "5                                0.000056                            0.000056   \n",
       "6                                0.000001                            0.000001   \n",
       "7                                0.000001                            0.000001   \n",
       "8                                0.000001                            0.000001   \n",
       "9                                0.000026                            0.000026   \n",
       "10                               0.000001                            0.000001   \n",
       "11                               0.012457                            0.012457   \n",
       "12                               0.000001                            0.000001   \n",
       "13                               0.000001                            0.000001   \n",
       "14                               0.000001                            0.000001   \n",
       "15                               0.030098                            0.030098   \n",
       "16                               0.000001                            0.000001   \n",
       "17                               0.160514                            0.160514   \n",
       "\n",
       "    feasibleToInfeasibleTermsRatio NoDisjunction  \\\n",
       "0                                       0.000001   \n",
       "1                                       0.000001   \n",
       "2                                       0.000001   \n",
       "3                                       0.000013   \n",
       "4                                       0.000001   \n",
       "5                                       0.000056   \n",
       "6                                       0.000001   \n",
       "7                                       0.000001   \n",
       "8                                       0.000001   \n",
       "9                                       0.000026   \n",
       "10                                      0.000001   \n",
       "11                                      0.012457   \n",
       "12                                      0.000001   \n",
       "13                                      0.000001   \n",
       "14                                      0.000001   \n",
       "15                                      0.030098   \n",
       "16                                      0.000001   \n",
       "17                                      0.160514   \n",
       "\n",
       "    feasibleToInfeasibleTermsRatio NoMatrix  \\\n",
       "0                                  0.000001   \n",
       "1                                  0.000001   \n",
       "2                                  0.000001   \n",
       "3                                  0.000013   \n",
       "4                                  0.000001   \n",
       "5                                  0.000056   \n",
       "6                                  0.000001   \n",
       "7                                  0.000001   \n",
       "8                                  0.000001   \n",
       "9                                  0.000026   \n",
       "10                                 0.000001   \n",
       "11                                 0.012457   \n",
       "12                                 0.000001   \n",
       "13                                 0.000001   \n",
       "14                                 0.000001   \n",
       "15                                 0.030098   \n",
       "16                                 0.000001   \n",
       "17                                 0.160514   \n",
       "\n",
       "    feasibleToInfeasibleTermsRatio NoTerm  \\\n",
       "0                                0.000001   \n",
       "1                                0.000001   \n",
       "2                                0.000001   \n",
       "3                                0.000013   \n",
       "4                                0.000001   \n",
       "5                                0.000056   \n",
       "6                                0.000001   \n",
       "7                                0.000001   \n",
       "8                                0.000001   \n",
       "9                                0.000026   \n",
       "10                               0.000001   \n",
       "11                               0.012457   \n",
       "12                               0.000001   \n",
       "13                               0.000001   \n",
       "14                               0.000001   \n",
       "15                               0.030098   \n",
       "16                               0.000001   \n",
       "17                               0.160514   \n",
       "\n",
       "    feasibleToInfeasibleTermsRatio NoBasis  instance  instanceIndex  \n",
       "0                                 0.000001         1             20  \n",
       "1                                 0.000001         1             20  \n",
       "2                                 0.000001         1             20  \n",
       "3                                 0.000013         1             19  \n",
       "4                                 0.000001         1             20  \n",
       "5                                 0.000056         1             12  \n",
       "6                                 0.000001         1             20  \n",
       "7                                 0.000001         1             20  \n",
       "8                                 0.000001         1             20  \n",
       "9                                 0.000026         1             12  \n",
       "10                                0.000001         1             18  \n",
       "11                                0.012457         1             10  \n",
       "12                                0.000001         1             20  \n",
       "13                                0.000001         1             20  \n",
       "14                                0.000001         1             20  \n",
       "15                                0.030098         1             11  \n",
       "16                                0.000001         1             18  \n",
       "17                                0.160514         1             14  \n",
       "\n",
       "[18 rows x 97 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>terms</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>Disjunction (New)</th>\n",
       "      <th>VPCs (New)</th>\n",
       "      <th>VPCs (Farkas)</th>\n",
       "      <th>VPCs (All)</th>\n",
       "      <th>VPCs (NoDisjunction)</th>\n",
       "      <th>VPCs (NoMatrix)</th>\n",
       "      <th>VPCs (NoTerm)</th>\n",
       "      <th>...</th>\n",
       "      <th>zeroInfeasibleToFeasibleTerms NoBasis</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio New</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio Farkas</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio All</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoDisjunction</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoMatrix</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoTerm</th>\n",
       "      <th>feasibleToInfeasibleTermsRatio NoBasis</th>\n",
       "      <th>instance</th>\n",
       "      <th>instanceIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.139849</td>\n",
       "      <td>0.139849</td>\n",
       "      <td>0.142625</td>\n",
       "      <td>0.142776</td>\n",
       "      <td>0.142776</td>\n",
       "      <td>0.142699</td>\n",
       "      <td>0.142776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.135827</td>\n",
       "      <td>0.135204</td>\n",
       "      <td>0.144141</td>\n",
       "      <td>0.144141</td>\n",
       "      <td>0.144141</td>\n",
       "      <td>0.144141</td>\n",
       "      <td>0.144141</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.683543</td>\n",
       "      <td>0.665729</td>\n",
       "      <td>0.579877</td>\n",
       "      <td>0.631318</td>\n",
       "      <td>0.604382</td>\n",
       "      <td>0.629848</td>\n",
       "      <td>0.631318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.665545</td>\n",
       "      <td>0.648594</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>0.686673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.697293</td>\n",
       "      <td>0.683371</td>\n",
       "      <td>0.221915</td>\n",
       "      <td>0.677023</td>\n",
       "      <td>0.677023</td>\n",
       "      <td>0.677023</td>\n",
       "      <td>0.677023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.101753</td>\n",
       "      <td>0.100893</td>\n",
       "      <td>0.081293</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>0.106109</td>\n",
       "      <td>0.097366</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.135393</td>\n",
       "      <td>0.134473</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>0.135029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.094838</td>\n",
       "      <td>0.044148</td>\n",
       "      <td>0.045303</td>\n",
       "      <td>0.045303</td>\n",
       "      <td>0.045303</td>\n",
       "      <td>0.045303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.650560</td>\n",
       "      <td>0.637210</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.386260</td>\n",
       "      <td>0.278970</td>\n",
       "      <td>0.303930</td>\n",
       "      <td>0.386260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.657222</td>\n",
       "      <td>0.644646</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>0.638456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.691134</td>\n",
       "      <td>0.672095</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>0.544757</td>\n",
       "      <td>0.544757</td>\n",
       "      <td>0.544757</td>\n",
       "      <td>0.544757</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.118144</td>\n",
       "      <td>0.108274</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.110269</td>\n",
       "      <td>0.099879</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>0.023225</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.116445</td>\n",
       "      <td>0.104373</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>matrix</td>\n",
       "      <td>0.588353</td>\n",
       "      <td>0.567842</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>0.030098</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>objective</td>\n",
       "      <td>0.586280</td>\n",
       "      <td>0.561469</td>\n",
       "      <td>0.332769</td>\n",
       "      <td>0.332769</td>\n",
       "      <td>0.332769</td>\n",
       "      <td>0.332769</td>\n",
       "      <td>0.332769</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>rhs</td>\n",
       "      <td>0.467465</td>\n",
       "      <td>0.452397</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows  97 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:57.168714Z",
     "start_time": "2025-05-01T19:44:57.157915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "short_fields = [\"Disjunction (New)\"] + [f\"VPCs ({gen_name})\" for gen_name in [\"New\", \"Farkas\", \"All\"]] + \\\n",
    "    [f\"Root Cuts ({gen_name})\" for gen_name in [\"None\", \"New\", \"Farkas\", \"All\"]]\n",
    "aggregations = {f: geometric_mean for f in short_fields}\n",
    "full_df[(full_df[\"terms\"] == 64) & (full_df[\"perturbation\"] == \"matrix\") & (full_df[\"degree\"] == 1)].groupby(\"instance\").agg(aggregations)"
   ],
   "id": "c8fb76a1440b3804",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Disjunction (New)  VPCs (New)  VPCs (Farkas)  VPCs (All)  \\\n",
       "instance                                                             \n",
       "bm23               0.685067    0.667193       0.585178    0.634388   \n",
       "\n",
       "          Root Cuts (None)  Root Cuts (New)  Root Cuts (Farkas)  \\\n",
       "instance                                                          \n",
       "bm23              0.400882          0.68401            0.631555   \n",
       "\n",
       "          Root Cuts (All)  \n",
       "instance                   \n",
       "bm23             0.663422  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disjunction (New)</th>\n",
       "      <th>VPCs (New)</th>\n",
       "      <th>VPCs (Farkas)</th>\n",
       "      <th>VPCs (All)</th>\n",
       "      <th>Root Cuts (None)</th>\n",
       "      <th>Root Cuts (New)</th>\n",
       "      <th>Root Cuts (Farkas)</th>\n",
       "      <th>Root Cuts (All)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm23</th>\n",
       "      <td>0.685067</td>\n",
       "      <td>0.667193</td>\n",
       "      <td>0.585178</td>\n",
       "      <td>0.634388</td>\n",
       "      <td>0.400882</td>\n",
       "      <td>0.68401</td>\n",
       "      <td>0.631555</td>\n",
       "      <td>0.663422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 224
  },
  {
   "cell_type": "markdown",
   "source": "## Check Termination Stats",
   "metadata": {
    "collapsed": false
   },
   "id": "33cb2bd47f9b2e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:58.079887Z",
     "start_time": "2025-05-01T19:44:58.074659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# additional filtering for dataframe on run time\n",
    "fields = [f\"terminationTime {gen}\" for gen in generators] + \\\n",
    "         [f\"terminationTimeImprovement {gen}\" for gen in generators if gen not in [\"None\", \"New\"]]\n",
    "# only check perturbed instances that solve to optimality and VPC didn't find optimal solution\n",
    "mask = (df[\"Disjunction (New)\"] < .9999) & (df[\"instanceIndex\"] > 0) & (optimality_gap(df, \"New\") <= 1e-4) & \\\n",
    "    (optimality_gap(df, \"None\") <= 1e-4) & (optimality_gap(df, \"Farkas\") <= 1e-4) & \\\n",
    "       (df[\"terminationTime None\"] > min_termination_time)\n",
    "\n",
    "# create time dataframe\n",
    "time_df = df.loc[mask, group_cols + id_cols + fields]"
   ],
   "id": "d8ffddad579b6222",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T19:44:58.543777Z",
     "start_time": "2025-05-01T19:44:58.534297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tmp = time_df.groupby([\"instance\", \"perturbation\", \"degree\", \"terms\"]).agg(\n",
    "    average_time_none=(f\"terminationTime None\", geometric_mean),\n",
    "    average_time_new=(f\"terminationTime New\", geometric_mean),\n",
    "    average_time_farkas=(f\"terminationTime Farkas\", geometric_mean),\n",
    "    average_time_all=(f\"terminationTime All\", geometric_mean),\n",
    "    average_improvement_farkas=(f\"terminationTimeImprovement Farkas\", \"mean\"),\n",
    "    average_improvement_all=(f\"terminationTimeImprovement All\", \"mean\"),\n",
    "    count=(f\"terminationTimeImprovement {gen}\", \"size\")\n",
    ").sort_values(\"average_improvement_all\", ascending=False).reset_index()\n",
    "tmp = tmp[(tmp[\"count\"] > 1) & (tmp['average_improvement_all'] > 0)]\n",
    "tmp[\"average_improvement_all_vs_farkas\"] = (tmp[\"average_time_farkas\"] - tmp[\"average_time_all\"]) / tmp[\"average_time_farkas\"]\n",
    "tmp.to_csv(os.path.join(out_fldr, \"high_perform_all.csv\"), index=False, mode=\"w\")\n",
    "tmp"
   ],
   "id": "5ca4f7bfe1b3ec1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [instance, perturbation, degree, terms, average_time_none, average_time_new, average_time_farkas, average_time_all, average_improvement_farkas, average_improvement_all, count, average_improvement_all_vs_farkas]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>degree</th>\n",
       "      <th>terms</th>\n",
       "      <th>average_time_none</th>\n",
       "      <th>average_time_new</th>\n",
       "      <th>average_time_farkas</th>\n",
       "      <th>average_time_all</th>\n",
       "      <th>average_improvement_farkas</th>\n",
       "      <th>average_improvement_all</th>\n",
       "      <th>count</th>\n",
       "      <th>average_improvement_all_vs_farkas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T14:04:06.728632Z",
     "start_time": "2025-04-30T14:04:06.722265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find ratios of all vs farkas\n",
    "# ijoc santanu and prachi paper on adding one cut and tree blows up\n",
    "# are the cuts getting stronger?\n",
    "# does time (excluding cut generation) improve when tightening improves"
   ],
   "id": "40925f52f82c669d",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c2d7c61d7a75f19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
